ropagation is theoretically capable of storing entire training sets; with enough hidden units, the algorithm could learn to assign a hidden unit to every distinct input pattern in the training set. It is a testament to the power of backpropagation that this actually happens in practice. Of course, that much power is undesirable. There are several ways to prevent backpropagation from resorting toa table-lookup scheme. One way is to stop training when a plateau has been reached, on the assumption that any other improvement will come through cheating. Another way is to add deliberately small amounts of noise to the training inputs. The noise should be enough to prevent memorization, but it should not be so much that it confuses the classifier. A third way to help generalization is to reduce the number of hidden units in the network, creating a bottleneck between the input and output layers. Confronted with a bottleneck, the network will be forced to come up with compact internal representations of its inputs. Finally, there is the issue of exceptions. In many domains, there are general rules, but there are also exceptions to the rules. For example, we can generally make the past tense of an English verb by adding -ed to it, but this is not true of verbs like sing, think, and eat. When we show many present and past tense pairs to a network, we would like it to generalize inspite of the exceptions but not to generalize so far that the exceptions are lost. Backpropagation performs fairly well in this regard, as do simple perceptrons, as reported in Rumelhart and Mc Clelland [1986a]. training set Performance > Training Time 18.2.4 Boltzmann Machines A Boltzmann machine is a variation on the idea of a Hopfield network. Recall that pairs of units in a Hopfield net are connected by symmetric weights. Units update their states asynchronously by looking at their local connections to other units. In addition to serving as content-addressable memories, Hopfield networks can solve