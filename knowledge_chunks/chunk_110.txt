er than one that satisfies the goalTest function. This is consistent with the notion that the goal state has the lowest heuristic value, since the distance to the goal is zero. We will also intermittently use the term objective function used by the optimization community to refer to the heuristic function. Let us consider the negation of the heuristic function h(n). Instead of looking for lower values of h(n), we can equivalently say that we are looking for higher values of h(n). That is, instead of a minimization problem, we have a maximization problem. As long as the moveGen function keeps generating nodes with better (higher) values, the search keeps stepping forward. Of the choices available, the algorithm picks the best one. In other words, the algorithm is performing steepest gradient ascent. Imagine you were blindfolded and left on a hillside, and asked to go to the top. What would your strategy be? Presumably, you might test the ground on all sides and take a step in the direction of the steepest gradient. And you would stop when the terrain in no direction is going upwards. That is precisely what the algorithm Hill Climbing is doing; moving along the steepest gradient of a terrain defined by the heuristic function. The idea is illustrated in Figure 3.8 below. FIGURE 3.8 Hill Climbing. Observe that while the terrain is defined by the heuristic function, and different heuristic functions define different landscapes , it is the moveGen function that independently determines the neighbourhood available to the search function. The moveGen function determines the set of points, both in number and location, in the landscape that become the neighbours of a given node. The heuristic function assigns a heuristic value to each point supplied by the moveGen function. The problem with climbing hills blindfolded is that one does not have a global view. We can only do local moves, and the best we can do is to choose the locally good options. If the hill we are asked to cl