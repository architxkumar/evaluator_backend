ropositional variables . ....,x, as illustrated in Figure 6.1. one can write the joint probability P(t, .......,) by inspection as a product of (Chain) conditional probabilities .(..........) = P(Vj Xc)P( i. x)P(t k1.t )Pl . tt/'iv Lv1 Pt'.1 Once such a network is constructed, an inference engine can use it to maintain and propagate beliefs. When new information is received, the etfect can be propagated throughout the network until equilibrium probabilities are reached. Pearl (1986. 1987) has proposed simplified methods for updating networks (trees and, more generally, graphs) of this type by fusing and propagating the effects of new evidence and beliefs such that equilibrium is reached in time proportional to the longest path through the network. At equilibrium, all propositions will have consistent probability assignments. Methods for graphs are more difficult. They require the use of dummy variables to transform them to equivalent tree structures tshich are theft easier to work with. To use the type of probabilistic inference we have been considering, it is first necessary to assign probabilities to all basic Facts in the knowkdgebstse. Thk, requires the definition of an appropriate sample space and the assignmenrof a priori and conditional probabilities. In addition, some method must be chosen to compute the combined probabilities when pooling evidence in ,a sequence of inference steps (such as Pearl's method). Finally, when 'the outcome of an inference chain result, in one or more proposed conclusions, the alternatives mu compared, and one or more selected on the basis of its likelihood 6.3 POSSIBLE WORLD REPRESENTATIONS In Section 5.4 the notion of possible worlds was introduced as a formalism through which an agent could view a set of propositions as being true in some worlds and false in others. We use the possible world concepts in this section to describe a method proposed by Nilsson ( f986) which generalizes first order logic in the modelling of uncertain