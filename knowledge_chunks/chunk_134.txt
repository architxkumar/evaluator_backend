viable option for large problems, search methods like Hill Climbing and Tabu Search work with bounded memories. While Hill Climbing is conceptually simple, it can get stuck on a local optimum. In Tabu Search, the attempt is to diversify search, as opposed to only following the steepest gradient, often moving to a node that is not the best successor, or even a better one. This allows it to move away from local optima, and the possibility of moving towards the global one is kept open. The steepest gradient ascent attempts to exploit the gradient information (Michalewicz and Fogel, 2004). To this, the Tabu Search adds an explorative component by trying to push the search into newer areas. It does this in a deterministic way, keeping a Tabu list of recent moves to be avoided. In this chapter, we look at randomized approaches to promoting exploration. First, we look at a way to randomize the Hill Climbing algorithm. Then, we look at other approaches motivated by the way random moves made in nature can lead to build up and preservation of good solutions. 4.1 Iterated Hill Climbing Working in the solution space, our search algorithms perturb current candidate solutions in search of better ones. The notion of a start node and a goal node in the state space is replaced by optimizing the value of the evaluation or heuristic function. The start node in the search tree has no particular significance when we are searching in the solution space. It is simply a candidate solution we begin with. For the Hill Climbing algorithm, this is the starting point of the steepest gradient ascent (or descent, if the problem is of minimization). Once the starting point is decided, the algorithm moves up (or down) along the steepest gradient, and terminates when the gradient becomes zero. The end point of the search is determined by the starting point, and the nature of the surface defined by the evaluation function. If the surface is monotonic then the end point is the global optimum; otherwis