 loop has P(x e)as its stationary distribution. Finally,
unless the CP Tscontain probabilities of 0 or 1 which can cause the state space to become
disconnected it is easy to see that q is ergodic. Hence, the samples generated by Gibbs
samplingwilleventually bedrawnfromthetrueposteriordistribution.
The final step is to show how to perform the general Gibbs sampling step sampling
X from P(X x ,e) in a Bayesian network. Recall from page 517 that avariable isinde-
i i i
pendent ofallothervariables givenits Markovblanket; hence,
P(x
(cid:2) x
,e) P(x
(cid:2) mb(X
)),
i i i i
where mb(X ) denotes the values of the variables in X s Markov blanket, MB(X ). As
i i i
shownin Exercise14.7,theprobabilityofavariablegivenits Markovblanketisproportional
totheprobability ofthevariablegivenitsparentstimestheprobabilityofeachchildgivenits
respective parents:
(cid:25)
P(x (cid:2) mb(X )) P(x (cid:2) parents(X )) P(y parents(Y )). (14.12)
i i i i j j
Yj Children(Xi)
Hence,toflipeachvariable X conditioned onits Markovblanket, thenumberofmultiplica-
i
tionsrequiredisequaltothenumberof X schildren.
i
Section14.6. Relational and First-Order Probability Models 539
Quality(B ) Quality(B )
1 2
Honesty(C ) Kindness(C ) Honesty(C ) Kindness(C )
Quality(B ) 1 1 2 2
1
Honesty(C ) Kindness(C )
1 1
Recommendation(C , B ) Recommendation(C , B )
1 1 2 1
Recommendation(C , B ) Recommendation(C , B ) Recommendation(C , B )
1 1 1 2 2 2
(a) (b)
Figure 14.17 (a) Bayes net for a single customer C recommending a single book B .
1 1
Honest(C )is Boolean,whiletheothervariableshaveintegervaluesfrom1to5. (b)Bayes
1
netwithtwocustomersandtwobooks.
14.6 RELATIONAL AND FIRST-ORDER PROBABILITY MODELS
In Chapter 8, we explained the representational advantages possessed by first-order logic in
comparison to propositional logic. First-order logic commits to the existence of objects and
relationsamongthemandcanexpressfactsaboutsomeoralloftheobjectsinadomain. This
oftenresultsinrepresentations thatarevastlymoreconcise t