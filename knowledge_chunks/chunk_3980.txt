ould it mean to you if you got some help? Person: Perhaps | could learn to get along with my mother. ELIZA: Tell me more about your family. Fig. 6.6 A Bit of a Dialogue with ELIZA Representing Knowledge Using Rules 141 (X me Y) (X you Y) (l remember X)} (Why do remember X just now?) (My {family-member} is Y) (Who else in your family is ?} (X {family-member} Y) (Tell me more about your family) Fig. 6.7 Some ELIZA-like rules ELIZA operated by matching the left sides of the rules against the user s last sentence and using the appropriate right side to generate a response. For example, if the user typed My brother is mean to me, ELIZA might respond, Who else in your family is mean to you? or Tell me more about your family. The rules were indexed by keywords so only a few had actually to be matched against a particular sentence. Some of the rules had no left side, so the rule could apply anywhere. These rules were used if no other rules matched and they generated replies such as Tell me more about that . Notice that the rules themselves cause a form of approximate matching to occur. The patterns ask about specific words in the user s sentence. They do not need to match entire sentences. Thus a great variety of sentences can be matched by a single rule, and the grammatical complexity of English is pretty much ignored. This accounts both for ELIZA s major strength, its ability to say something fairly reasonable almost all of the time, and its major weakness, the superficiality of its understanding and its ability to be led completely astray. Approximate matching can easily lead to both these results. As if the matching process were not already complicated enough, recall the frame problem mentioned in Chapter 4. One way of dealing with the frame problem is to avoid storing entire state descriptions at each node but instead to store only the changes from the previous node. If this is done, the matching process will have to be modified to scan backward from a node through its