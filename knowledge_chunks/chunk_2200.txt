 asa
1 n
fraction of the total, to converge in the limit to its expected value according to the sampling
probability:
N (x ,...,x )
PS 1 n
lim S (x ,...,x ) P(x ,...,x ). (14.5)
PS 1 n 1 n
N N
For example, consider the event produced earlier: true,false,true,true . The sampling
probability forthiseventis
S (true,false,true,true) 0.5 0.9 0.8 0.9 0.324.
PS
Hence,inthelimitoflarge N,weexpect32.4 ofthesamplestobeofthisevent.
Wheneverweuseanapproximateequality( )inwhatfollows,wemeanitinexactly
this sense that the estimated probability becomes exact in the large-sample limit. Such an
estimate is called consistent. For example, one can produce a consistent estimate of the
CONSISTENT
probability ofanypartially specifiedevent x ,...,x ,wherem n,asfollows:
1 m
P(x ,...,x ) N (x ,...,x ) N . (14.6)
1 m PS 1 m
That is, the probability of the event can be estimated as the fraction of all complete events
generated by the sampling process that match the partially specified event. For example, if
532 Chapter 14. Probabilistic Reasoning
we generate 1000 samples from the sprinkler network, and 511 of them have Rain true,
thentheestimatedprobability ofrain,writtenas
P (Rain true),is0.511.
Rejectionsamplingin Bayesian networks
REJECTION Rejectionsamplingisageneralmethodforproducingsamplesfromahard-to-sampledistri-
SAMPLING
bution given an easy-to-sample distribution. In its simplest form, it can be used to compute
conditional probabilities that is,todetermine P(X e). The REJECTION-SAMPLING algo-
rithmisshownin Figure14.14. First,itgeneratessamplesfromthepriordistributionspecified
bythenetwork. Then,itrejectsallthosethatdonotmatchtheevidence. Finally,theestimate
P (X x e)isobtained bycountinghowoften X xoccursintheremaining samples.
Let P (X e)betheestimateddistributionthatthealgorithmreturns.
Fromthedefinition
ofthealgorithm, wehave
N (X,e)
P (X e) N (X,e) PS .
PS
N (e)
PS
From Equation(14.6),thisbecomes
P(X,e)
P (X e) P(X e).
P(e)
Thatis,rejection samplingproduces aconsistent estimate