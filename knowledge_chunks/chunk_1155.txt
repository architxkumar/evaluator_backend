d go into loops amplifying a small bit of evidence. Systems like MYCIN that operate in a modular rule baselike fashion, restrict themselves to abductive reasoning only. In doing so, however, one has to forgo the benefits of prediction. One such benefit is the explaining away that can be done with predictive reasoning. For example, if malaria implies fever and if a viral infection can lead to fever too, then finding that the patient has a viral fever explains the fever, and makes belief that the patient has malaria less credible. We look at an interesting example given by Judea Pearl (1988) that highlights this kind of interaction between inferences. Suppose you have an alarm system installed in your home, and you get a call from your neighbour that the alarm is ringing. You are about to conclude that your house has been burgled and rush home when you happen to glance at your monitor? which is showing news that there has been an earthquake in the region. You remember that the last time there was an earthquake too, the alarm had gone off, and this decreases your belief in the possibility of a burglary having happened. Now consider what has happened. If you had a rule (alarm burglary), then if your belief in alarm goes up, then normally your belief in burglary should go up too. But the opposite is happening here. The news of the earthquake has confirmed the fact that the alarm has sounded, but at the same time alleviated your fears that a burglary might have happened. A variation is that the neighbour may be unreliable, having a tendency for tasteless pranks. You would then have to gather more evidence that the alarm actually sounded. You could try another neighbour but she might be having loud music playing in her house and not quite sure. If you did get some response from her you would still have to worry about combining the evidences together, in a scenario where there may not be too much data on the conditional probabilities needed. This pull between modularity and