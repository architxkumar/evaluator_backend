bability of an Note that equation 6.5 event to the probability of its negation. P(HIE) I P(-HIE) and P(H) / PIN). The ratio of the probability of an event E divided by the probability of its negation is called the odds of the event and are denoted as 0(E). The remaining ratio P(EIH) in equation 6.5 is known as the likelihood ratio of E with respect to H. P(EIH) Using these two new terms, the odds-likelihood We denote this quantity by L(EIH). form of Bayes' Rule for equation 6.5 may be written as 0(HIE) = L(EIH )0(H) This form of Bayes' Rule suggests how to compute the posterior odds 0(t IIE) from the prior odds on H. 0(H). That value is proportional to the likelihood L(EIH). When L(EIH) is equal to one, the knowledge that E is true has no effect on the odds of H. Values of L(EIH) less than or greater than one decrease or increase the cannot be computed. estimates may still be odds correspondingly. When L(EIH) made by an expert having some knowledge of H and E. Estimating the ratio rather than the individual probabilities appears to be easier for individuals in such cases. This is sometimes done when developing expert systems where more reliable probabilities are not available. In the example cited above, Dl is either true or false, and P(Dfl E) is the interpretation which assigns a measure of confidence that Dl is true when it is known that E is true. There is a similarity between E, P(DI IE) and modus ponens discussed in Chapter 4. For example. when E is known to be true and Dl and F are known to be related, one concludes the truth of Dl with a confidence level P(DI!E). One might wonder if it would not be simpler to assign probabilities to as Sec. 6.2 Baye.ian Probabilistic Inference 111 many ground atoms E1, E2, . - . , Ek as possible, and compute inferred probabilities (probabilities of Ej -. H and II) directly from these. The answer is that in general this is not possible. To compute an inferred probability requires a knowledge of the joint distributions of the 