ose which node to expand next on the basis not only of how good the node itself looks (as measured by / ), but also on the basis of how good the path to the node was. By incorporating g into f . we will not always choose as our next node to expand the node that appears to be closest to the goal. This is useful if we care about the path we find. If, on the ather hand, we only care about getting to a solution somehow, we can define g always to be 0, thus always choosing the node that seems closest to a goal. If we want to find a path involving the fewest number of steps, then we set the cost of going from a node to its successor as a constant. usually 1. If, on the other hand, we want to find the cheapest path and some operators cost more than others, then we set the * This second check guarantees that the algorithm will terminate even if there are cycles in the graph. If there is a cycle. then the second time that a given node is visited, the path will be no better than the first time and so propagation will stop. Heuristic Search Techniques 61 EAWMGCigebadss + ohn RERIIRLAAe | Ait carb AROMA cost of going from one node to another to reflect those costs. Thus the A* algorithm can be used whether we are interested in finding a minimal-cost overall path or simply any path as quickly as possible. The second observation involves 4 , the estimator of h, the distance of a node to the goal. If i is a perfect estimator of h, then A* will converge isnmediately to the goal with no search. The better Ai is, the closer we will get to that direct approach. If, on the other hand, the value of h is always 0, the search will be controlled by g. If the value of g is also 0, the search strategy will be random. If the value of g is always 1, the search will be breadth first. All nodes on one level will have lower g values, and thus lower f values than will all nodes on the next level. What if, on the other hand, / is neither perfect nor 0? Can we say anything interesting about the beha