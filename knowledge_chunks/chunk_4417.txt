many others are learnt unsupervised. A typical example of the latter is the way in which an infant learns to recognize the objects and people around it. A Kohonen network is a non-recurrent (feedforward) network which comprises two layers the input layer and an output layer. The latter is referred to as the Kohonen layer and is said to constitute Kohonen neurons. As can be seen in Fig. 18.20 (a) every neuron of the input layer is connected to every Kohonen neuron. The Kohonen layer could be of different dimensions. Fig. 18.20 (b) depicts a one dimensional Kohonen layer while Fig. 18.20 (c) shows the layer in a two-dimensional configuration. One could imagine other geometrical shapes for the Kohonen layer, like for instance, a hexagon. Each connection is associated with a weight w, that is variable. The network is presented with continuous values that represent patterns that are to be learnt. These inputs can be looked upon as areal valued vector (x X), Xz, ... .X,). The output is not specified as the learning is unsupervised. Connectionist Models 395 Kohonen Layer Kohonen Layer input Layer (0) A Kohonen network {b) One-dimensional Kohonen Layer O}O OO|OJO OO O|OO|O OO C/O O OOOO0O0O OOOO 0 OC}O OVO|O O OC]O/O OCLO|OLOl OJ}O}O O O O {c) Two-dimensional Kohonen Layer Fig. 18.20 Algorithm 1. Initialize the weights w,, for i = 1 to n (on the input side) and j = | to m (on the output side) with real random values. Two more parameters, viz. the neighbourhood and the learning rate are initialized. The neigborhood is defined as a radius r as depicted in Fig. 18.20 (b) and (c). It is initialized to a higher value say 3 while the learning rate @ is selected as a high value (around 0.8) in the interval (0, 1). For all the input vectors do the following: 2. Select an input vector at random. Present the selected input vector x = (Xj, X, ... , Xq): 3. Find that Kohonen neuron j that has its associated weight vector (W);, W , ;,..,W,j) closest to the input vector x. Closeness coul