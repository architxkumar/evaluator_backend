Suspect Babbitt IVA [12] A [14] > [9] {A7, A2, AB |A7, A2, AB} [10] Prime Suspect Cabot A 112] A [13] > [10] {A7, A2, Aa AT, A2, Ad} (11 A, B,C not oniy suspects {A8} {A8! {AB} [12] Not prime suspect Abboit {2] > [12] AQ} A2}, {A8} [11] > [412] AB} 19] > [12] {AT, A2, AB [10] > [12] {A7, A2, Ad [13 Not prime suspect Babbitt [41> [13] {A4} Ad}, {A8} [11] > [13] (A8} [8] > [13] {A7, Ad, AB) [10] > [13] AT, A4, A2} {14] Not prime suspect Cabot [6] > [14] A6} {A6}, {A8} [14] > [14] AB} [8] > [14] A7, AA, AG) (9] > [14] AT, A2, AB' Fig. 7.14 Nodes and Their justifications and Labels Symbolic Reasoning Under Uncertainty 169 (eh 5 SAR LISELI NASSP MNES NEE TORT There are several things to notice about this example: * Nodes muy have several justifications if there are several possible reasons for believing then. This is the case for nodes 12, 13, and 14. Recall that when we were using a JTMS, a node was labeled IN if it had at least one valid justification. Using an ATMS, a node wil! end up being labeled with a consistent context if it has at least one justification that can occur in a consistent context. The label assignment process is sometimes complicated. We describe it in more detail below. Suppose that a problem-solving program first created nodes 1 through 14, representing the various dependencies among them without committing to which of them it currently believes. It can indicate known contradictions by marking as no good the context: A, B, Care the only suspects; A, B, C are not the only suspects: {A7, A8} The ATMS would then assign the labels shown in the figure. Let s consider the case of node 12. We generate four possible labels, one for each justification. But we want to assign to the node a label that contains just the greatest lower bounds of all the contexts in which it can,occur, since they implicitly encode the superset contexts. The label {A2} is the greatest lower bound of the first, third, and fourth label, and {A8} is the same for the second label. Th