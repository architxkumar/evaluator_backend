n by, () ingP eu mali if j allowed, (f) RO ) D pl TOF Oma ) (4.10) allowed, (f) 0 otherwise where allowed ,(f) tabu,() , and nj 1 distance(city,, city;) also called the visibility of cityrom city;. The algorithm maintains a set tabu,(t) for each ant k, that contains the cities already visited by the ant in that cycle of tour construction. In the TSP-ACO algorithm, the amount of pheromone on a segment gives an indication of the goodness of a move, based on the accumulated experience of the population. To achieve this, the amount of pheromone deposited by each ant is directly determined by the goodness (1 cost) of the solution found. Real ants move at a constant speed leaving behind a constant amount of solution. The ant colony manages to reinforce good solutions, simply because of the fact that ants using shorter routes to food come back faster, hence replenishing the pheromone levels faster. The ACO algorithm then can be seen as a parallel, randomized search algorithm that converges towards good solutions by a process of learning in which, each agent communicates some information about the goodness of solution components to a common pool. As more and more agents explore the good components, more agents use them to build solutions. In some sense, this behaviour is similar to the one in GA, except that there it is the solutions themselves that make up the populations. In ACO, the solutions are not coded, but simple agents repeatedly construct solutions, exploiting the information (or experience) of earlier attempts by the entire population. The ACO algorithm also has similarities with the Simulated Annealing algorithm. In both, a move is made probabilistically to a neighbour. SA works with a single solution, perturbing the solution probabilistically. The SA algorithm first chooses a neighbour and then decides whether to move to it or not. ACO looks at all neighbours to pick one to move to. In SA, the decision is based only on the goodness of the move determined by AE 