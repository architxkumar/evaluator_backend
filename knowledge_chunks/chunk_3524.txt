permit the construction of deeper semantic structures than the generative grammars. Case, semantic, and systemic grammars were given as examples of grammars that are also more semantic oriented than the generative grammars. Lexicons were described, and the role they play in NL systems given. Basic parsing techniques were examined. We locked at simple transition networks, recursive transition networks, and the versatile ATN. The ATN includes tests and actions as part of the arc components and special registers to help in building syntactic structures With an ATN, extensive semantic analysis is even possible. We defined top-down bottom-up, deterministic, and nondeterministic parsing methods, and an example of a simple PROLOG parser was also discussed. We next looked at the semantic interpretation process and discussed two broad approi'ches, namely the lexical and compositional semantic approaches. These approaches are also identified with the type of target knowledge structures generated. In the compositional semantics approach. logical forms were generated, whereas in the lexical semantics approach, conceptual dependency or similar network structures are created. Language generation is approximately the opposite of the understanding analysis process, although more difficult. Not only must a system decide what to say but how to say it. Generation falls naturally into three areas, content determination. text planning, and text realization. Two general approaches were presented. They are like the inverses of the lexical and compositional semantic analvsis processes. The KAMP system uses an elaborate planning process to determine what, when. and how to state some concepts. The system simulates a robot giving advice to a human helper in the repair of air compressors. At the other. extreme, the BABEL system generates output text from conceptual dependency and script structures. We concluded the chapter with a look at three s stems of somewhat disparate architectures: the L