ame group are more similar than data points across groups. Such groups discovered by a clustering technique are referred to as clusters. The algorithm K-means for clustering partitions a data set into k clusters, where k is a user defined number. It was first devised by Stuart Lloyd (1957) and is also known as Llyod s algorithm. The clusters generated by K-means are disjoint, in that each data point would be uniquely assigned to one cluster; further, algorithm K-means ensures that no points are left unassigned. In the case of a clustering of our dataset X, we may define the clustering problem declaratively, based on the desired properties of the groups output by the clustering as follows: f one picks a random pair of objects that both belong to the same group (cluster) and another pair of objects that belong to different groups, it should be highly likely that the distance between the former pair is much lesser than the distance between the latter pair. K-means attempts to achieve such a property in generating k groups from the dataset X x,, X2, ..., Xp , in an iterative fashion. After any iteration, there would be a set of k clusters, that we denote by C, Co, ..., C, . Within each iteration, K-means refines the clusters from the previous iteration by optimizing the following objective function (for all the clusters): O(cluster(.), WO) YE (dq; M(cluster(x,))) (18.47) 1 Sign where cluster( x;) denotes the cluster to which x; belongs and p(c) denotes a representative point, or the centroid, for the cluster c, and d(.,.) denotes the distance function (L2 norm). That is, the algorithm strives to minimize the sum of the distances of each point to the centroid of the cluster to which the point belongs. In order to minimize this objective function, we could change one or both of the following, moving from one iteration to the next: 1. Assignments of data points to clusters, i.e., cluster(.) function 2. Choosing the centroid for a cluster, i.e., y(.) function. K-means adopt