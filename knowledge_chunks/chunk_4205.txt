ugh this sentence, taken in isolation, is ambiguous, it would usually not be interpreted as being ambiguous by a human listener in a specific context. Clues, both from previous sentences and from the physical context in which the sentence occurs, usually make one of these interpretations appear to be correct. The problem, though, from a processing standpoint, is how to encode this contextual information and how to exploit it while processing each new sentence. Notice that English, in all its glory, has the properties of both of these last two examples; it involves a many-to-many mapping, in which there are many ways to say the same thing and a given statement may have many meanings. Level of Interaction among Components In most interesting understanding contexts, each input is composed of several components (lines, words, symbols, or whatever). The mapping process is the simplest if each component can be mapped without concern for the other components of the statement. Otherwise, as the number of interactions increases, so does the complexity of the mapping. Programming languages provide good examples of languages in which there is very little interaction among the components of an input. For example, Fig. 14.4 shows how changing one word of a statement requires only a single change to one node of the corresponding parse tree. Ls 276 Artificial Intelligence } o N Om A BC J A BC J o A AN cos sqrt cos sant Q s N Q cos R R x= A*B+C* xis A*B+C* (D + COS(Q) * SQRT(SIN(R))) (D + COS(Q) * SART(COS(R))) Fig. 14.4 Little Interaction among Components In many natural language sentences, on the other hand, changing a single word can alter not just a single node of the interpretation, but rather its entire structure. An example of this is shown in Fig. 14.5. (The triangles in the figure indicate substructures whose further decomposition is not important.) As these examples show, the components of an English sentence typically interact more heavily with each other than do the i c