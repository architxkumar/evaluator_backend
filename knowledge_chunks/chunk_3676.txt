 complete the description, the learner attempts to combine the new positive instance with each cluster by merging as before, but only if the resultant merge is compatible with all negative instances (one. in this case). If the new instance cannot be merged with any existing cluster without creating an inconsistency, a new cluster is created. Merging the new instance with the first cluster results in the same cluster. Merging it with the second cluster produces a new, more general cluster description of yellow. The final frame obtained is as follows. concept_name:(tall flower or yellow object) positive part: cluster: description:(tall flower) :examples:(tall fat brown flower) (green tall skinny flower) (fat yellow flower tall) cluater:description:(yellow) :examples:(skinny short yellow weed) (fat yellow flower tall) negative part: :examples:(tall fat brown weed) The completed concept now matches the target concept 'tall flower or yellow object." 394 Learning by Induction Chap. 18 The above example illustrates the basic cycle but omits some important factors. First, the order in which the training instances are presented to the learner is important. Different orders, in general, will result in different descriptions and may require different numbers of training instances to arrive at the target concept. Second. when splitting and rebuilding clusters after encountering a negative example, it is possible to build clusters which are not concise or maximal in the sense that some of the clusters could be merged without becoming inconsistent. Therefore, after rebuilding new clusters it is necessary to check for this maximality and merge clusters where possible without violating the inconsistency condition. Blocks World Example Another brief example will illustrate this point. Here we want to learn the concept "something that is either yellow or spherical." For this, we use the following training instances from a blocks world. (yellow pyramid soft large +) (blue sphere soft 