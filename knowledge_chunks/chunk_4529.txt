f generations. Mutation is realized by flipping the value of a randomly selected gene in a chromosome. Mutation in the present case, if p,, permits, can be effected by randomly selecting one of the three bits representing the genes and flipping its state. For instance the chromosome {0, 1, 0} could mutate to any of {1, 1, 0} or (0, 0, 0} or {0, 1, 1} patterns randomly. (1, 0, 0} and (1, 1, 1} Since we have not transgressed through many generations we assume mutation will not occur at the moment. Thus the resultant next generation population along with the necessary statistics is shown in Fig. 23.2. Resultant Solutions Si {0,1,0} {1,0,0} {1,4,1} {1,1,0} = Maximum Fig. 23.2 Statistics of the next generation of solutions As can be seen (fortunately) we have hit upon the maximum value of fitness for the chromosome {1, 1, 1}. Since this is the optima] value we go no further in the process of creating future generations for this problem. The procedure has thus yielded the solution {1, 1, 1} indicating that when all units are tumed ON, the resultant profit is the highest. 462 Artificial Intelligence Naturally this, no doubt is an obvious conclusion but the above example was used only to exemplify the manner in which a GA can be applied to a problem. 23.2.2 Preblem II Learning: Generalization of an Input-Output table Machine learning can be attributed, among other phenomena, to grabbing a generalization of a truth table. By generalization. in the present case, we mean, learn and derive a function that can represent a table. Consider the Table 23.3 given below that has three inputs @, b, c and an output z. Table 23.3 Input-Output table to be learned inputs b N a 0 0 0 0 \ 1 1 1 Mr OOF RK OO ~Oe DH o-ofs et Oe Oe How do we make the GA generalize and arrive at a function that can satisfy all the input-output mappings? The first step that requires some ingenuity is to make the problem GA compatible. We do this by introducing three weights w,, w, and w, and find the weighted sum