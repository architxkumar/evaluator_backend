matching with observed data. Readers familiar with probability and statistics, would notice the similarity of the curve in Figure 17.26 with the well known Gaussian or normal distribution, characterized by two parameters the mean value and the standard distribution. There are other distributions as well that have been studied by people working in pattern recognition, machine learning, and many other applications of probability and statistics. We shall not pursue the study of probability distributions, but instead turn our attention to how different random variables influence the probabilities of each other, and how one can make some sort of probabilistic influences. 17.5.1 Conditional Probabilities and Bayesian Reasoning When we say that the probability of a proposition being true is a certain value, it is in fact backed up by all the world knowledge that the agent has brought to fore. We think of P(a) as the probability of a being true. This statement really sums up all our Knowledge about the world in a single number. In that sense, it is in fact a short form for P(a k) read as the probability of a being true given k where k stands for everything that we know about the world but are not in a position to articulate (Pearl, 1988). In that sense, probabilities are always conditional on what we know already. In practice, we would like to exploit any information that we receive to revise our belief (probability) estimates. This is akin to making inferences in logic. For example, seeing a big crowd already waiting, one may revise one s chances of quickly finding a seat in a favourite restaurant. Reading a review of a new movie may change our belief of how enjoyable the movie would be. Watching the audience come out of the previous show may further influence our belief. A medical doctor may give greater credence to the belief that a patient is afflicted by a particular disease, if an epidemic has started. As more and more cards are played, a bridge player forms stronger 