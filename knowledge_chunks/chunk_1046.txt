e process of summarization can be broken down into three major steps. The first is topic identification, the goal of which is to return the highest scoring units (sentences) based on their suitability for inclusion in the summary. The suitability is estimated using a combination of factors, such as positional criteria (headings, titles and starting sentences may be more important than others), cue phrase indicator criteria (a sentence beginning with the key contribution of this paper is is likely to be important) and word frequency criteria (sentences having high frequencies of words that discriminate the text from others are likely to be more important). More such criteria, as well as an account of a comparison of their effectiveness based on empirical evaluations, are discussed in detail in Ed Hovy (Hovy, 2005). The second step is interpretation or topic fusion. This is an important step for abstractive summarization, and involves the use of information extraction approaches to fill in the slots of domain-specific templates, which capture the essential content that needs to be rendered into the summarised text. Thanks to knowledge acquisition bottlenecks, this is a hard problem and has been a major stumbling block in the way of building abstractive summarizers. The third and final step is summary generation, which uses Natural Language Generation techniques to render the filled-in templates resulting from the previous step to text. It may be noted that the role of interpretation and summary generation is minimal in the case of extractive summarization. 16.4 Natural Language Generation NLG is complementary to NLU, in that it aims at constructing natural language text from a variety of nontextual representations like maps, graphs, tables and temporal data. Such a conversion could be motivated by one or more distinct communication goals. An example of a communication goal is to make the information in a data like a map accessible to the blind. This can be achieved by