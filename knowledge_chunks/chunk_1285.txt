 do a fixed number of iterations, but then one should have an idea of how many. A method that is often used is to separate the training data from the test data or the validation data. Performance on the test data can be used to decide when to terminate, while the training data is used to update the weights. A procedure of cross validation is often used, in which by turns, a fraction of the data is used for validation as the rest is used for training. Different subsets are chosen to form the training set by rotation. An important question that arises is on the role of the hidden neurons. How do they contribute to learning more complex concepts than a single layer system? It has been demonstrated that a layered network with a single hidden layer and an output layer using the linear functions capture all bounded functions. With an additional hidden layer, one can represent any arbitrary function with any accuracy. In general, it is felt that given a sufficient number of neurons, any complex function can be captured using a feedforward neural network with one hidden layer, where both the hidden and output layers use the sigmoid function. The process becomes significantly more efficient with an additional hidden layer. Designing an artificial neural network essentially boils down to choosing the number of hidden neurons. Once the features of the data are decided, the number of input layer neurons gets automatically determined. Likewise, when the target classes are defined, so does the output layer. The hidden neurons contribute to problem solving by creating intermediate representations, which in turn are used to construct the decision surfaces by the output layer. Remember that the output neurons get the signal only from the hidden layer. The number of neurons in the hidden layer should be enough to create all the intermediate representations needed to create the complex decision surfaces the problem requires. At the same time, the number must not be too large because t