 it as a program that somehow searches through combinations efficiently and nothing more than that. It only knows how to choose a move, given a board position. Let us try and imagine what would make it seem worthy of being called intelligent. If the program were more like a creature (Grand, 2001) then humans are more likely to accept it as an intelligent creature. If such a creature had a chess playing ability, had some kind of a sense of identity, and was in some sense aware that it was playing chess, if it could converse in natural language, if it could comment upon your moves, if it had a memory of past interactions, if it was connected to other things besides chess ( the weather is too good to play inside ), if it had internal goals tied up with emotions and moods then such a program would surely command more respect. Such a program would know a lot. How can we build such an intelligent and articulate chess playing agent? An intelligent program must have a considerable amount of knowledge and it must have the faculty of some kind of language, a means for knowledge exchange. What kind of knowledge would the chess-playing agent need? It must know that chess is a game that it is playing. It must know that there are other things than chess. How does it know that it , amongst other things, is there playing chess ? It must have a model of the world and must know facts in the world. It must know about the processes that go on in the world and the changes they ensue. To know a world is to have a representation of the concepts involved and the relations between them; for example, this is an apple and apples are sweet and apples are fruit and fruits have seeds and therefore apples have seeds , and so on. Such knowledge is traditionally referred to as an ontology . We can also call such knowledge as semantic knowledge or knowledge about the meaning of terms. Ontologies are categorizations of things, defining them relative to each other, separating categories into classes b