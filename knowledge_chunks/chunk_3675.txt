w object) positive part: cluster: description: (tall, flower) :examples:(tall fat brown flower) (green tall skinny flower) negative part: examples: The next training example is also a positive one. Therefore, the set intersection of this example and the current description is formed when the learner is presented with this example. The resultant intersection and new hypothesis is an over generalization, namely, the null set, which stands for anything. concept_name:(tall flower or yellow object) positive part: cluster:d.scription:() :examples:(tall fat brown flower) (green tall skinny flower) (skinny short yellow weed) negative part: examples: The fourth instance is a negative one. This instance is inconsistent with the current hypothesis which includes anything. Consequently, the learner must revise its hypothesis to exclude this last instance. Sec. 18.6 Example of an Inductive Learner 393 It does this by splitting the first cluster into two new clusters which are then both compatible with the negative instance. Each new cluster corresponds to a disjunctive term in this description. To build the new clusters, the learner uses the three remembered examples from the first cluster. It merges the examples in such a way that each merge produces new consistent clusters. After merging we get the following revised frame. concept_name:(ta Ii flower or yellow object) positive_part: cluster:description:(tal I flower) :examples-(tall fat brown flower) (green tall skinny flower) cluster: description: (skinny short yellow weed) :examples: (skinny short yellow weed) negative part: :examples:(tall fat brown weed) The reader should verify that this new description has now excluded the negative instance. The next training example is all that is required to arrive at the target concept. To complete the description, the learner attempts to combine the new positive instance with each cluster by merging as before, but only if the resultant merge is compatible with all negative instances (