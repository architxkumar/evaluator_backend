pying the first cluster and then successively merging or copying the other clusters in combination. Of course, a merge can be completed only when an inconsistency does not result. The first two clusters cannot be merged as we know from the above. The first and third clusters can be merged to give yellow. The second and fourth clusters can also be merged to produce sphere. These are the only merges that can be made that are compatible with both negative examples. The final frame then is given as concept _name:(yellow or spherical object) positive part: cluster: description: (yellow) :examples: (yellow cube soft large) (yellow pyramid hard small) (yellow pyramid soft large) cluster: description: (sphere) :examples: (green large sphere hard) (blue sphere soft small) negative part: :exsmplee:(blue cube soft small) (blue pyramid soft large) Sec. 18.6 Example of an Inductive Learner 397 It may have been noticed already by the astute reader that there is no reason why negative-part clusters could not be created as well. Allowing this more symmetric structure permits the creation of a broader range of concepts such as 'neither yellow nor spherical" as well as the positive type of concepts created above. This is implemented by building clusters in the negative part of the frame using the negative examples in the same way as the positive examples. In building both descriptions concurrently, care must be taken to maintain consistency between the positive and negative parts. Each time a negative example is presented, it is added to the negative part of the model, and a check is made against each cluster in the positive part of the model for inconsistencies. Any of the clusters which are inconsistent are split into clusters which are maximal and consistent and which contain all the original examples among them. We leave the details as an exercise. Network Representations It is also possible to build clusters of network representation structures and to learn structural descriptio