hen all the children of the current node become costlier than the upper bound. Observe that like DFS, it maintains only one path in its memory, thus requiring linear space. Its time complexity is however difficult to characterize. One can imagine that in a large search space, it will often switch attention, sometimes even between the same two paths. This has been corroborated by experimental results, where it was found to take considerably longer solving problems, specially those where even though the problem only grows polynomially, the number of different paths grow combinatorially. Like DA , RBFS ends up repeatedly visiting the same nodes again and again, leading to an increase in the computation time. This is the price both the algorithms have to pay for saving on space. Backed up fvalue New Search Lowest f-values are backed up at each level e S FIGURE 5.23 Recursive Best First Search rolls back a path when it is not looking the best. We now explore some other approaches to reducing memory, starting with the list CLOSED. Maintaining the CLOSED list has two benefits. One, that it keeps a check on the nodes already visited, and prevents the search from expanding them again and again. And two, it is the means for reconstructing the path after the solution is found. In the next section, we look at an algorithm that prunes the CLOSED list, and still does both but, again, at the expense of more time complexity. Box 5.1: When is CLOSED a problem? One would expect that the size of the CLOSED list should be less of a concern than the size of OPEN, given the fact that in an exponentially growing search space, the OPEN is likely to be much bigger than CLOSED. There are, however, problems where the list CLOSED could be the main memory bottleneck. These are problems that are combinatorial in nature. This happens when the underlying search space is a graph, for example in the route finding problem illustrated here. rN iN oN 7 ABCDHL LA D) ABCGHL ABCGKL ABFGHL (r rc Y 7 ABFGKL