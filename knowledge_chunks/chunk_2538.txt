ues wehavediscussed.
3 300 Boosted Virtual Shape
NN Hidden Le Net Le Net SVM SVM Match
Errorrate(pct.) 2.4 1.6 0.9 0.7 1.1 0.56 0.63
Runtime(millisec digit) 1000 10 30 50 2000 200
Memoryrequirements (Mbyte) 12 .49 .012 .21 11
Trainingtime(days) 0 7 14 30 10 rejectedtoreach0.5 error 8.1 3.2 1.8 0.5 1.8
18.11.2 Casestudy: Wordsenses and houseprices
In a textbook weneed to deal with simple, toy data to get the ideas across: a small data set,
usually in two dimensions. But in practical applications of machine learning, the data set
is usually large, multidimensional, and messy. The data are not handed to the analyst in a
prepackaged setof(x,y)values;rathertheanalystneedstogooutandacquiretherightdata.
There is a task to be accomplished, and most of the engineering problem is deciding what
data are necessary to accomplish the task; a smaller part is choosing and implementing an
756 Chapter 18. Learningfrom Examples
1
0.95
0.9
0.85
0.8
0.75
1 10 100 1000
tes
tset
no
tcerroc
noitropor P
Training set size (millions of words)
Figure18.37 Learningcurvesforfivelearningalgorithmsona commontask. Notethat
there appears to be more room for improvementin the horizontal direction (more training
data) than in the vertical direction (different machine learning algorithm). Adapted from
Bankoand Brill(2001).
appropriate machine learning method toprocess the data. Figure18.37 showsatypical real-
world example, comparing five learning algorithms on the task of word-sense classification
(given a sentence such as The bank folded, classify the word bank as money-bank or river-bank ). The point is that machine learning researchers have focused mainly on the
verticaldirection: Can Iinventanewlearningalgorithm thatperformsbetterthanpreviously
published algorithms on a standard training set of 1 million words? But the graph shows
there is more room for improvement in the horizontal direction: instead of inventing a new
algorithm,all Ineedtodoisgather10millionwordsoftrainingdata;eventheworstalgori