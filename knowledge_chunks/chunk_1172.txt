in. The expected costs are lowest for sz and ss, since they are closest to the goal node and the policy picks the action taking them to the goal node. The policy 79g is the other interesting policy (that could be optimal). The reader should also verify that any other policy is going to be more expensive. For 712g on the action at state s, is different and so the corresponding equation is, VPs) Ply, a1, SCC, 43. 82) VP 5y) Ply, a4. 1C(S1, 3, 83) V 53) 0.8 10 V" s,) 0.2 6 VS (s;) The rest of the equations are the same and the values for V"2 (s), ..., V7 (s7) are, VG (38.2075, 24.7908, 45.8741, 45.8741, 25.5211, 53.3027, 53.3027 One can see that the lower costs of actions a;2 and agg are reflected in the overall expected costs. The costs are higher than the deterministic costs because the probabilities of heading away from the path to the goal are significant. Let us modify the probabilities a little to get a sense of how these probabilities influence expected costs. Let us change the probabilities of the actions from s4 and s7 to much higher probabilities for heading towards s,, as opposed to staying put. Table 17.14 The modified probabilities for a,4 and a74 a41 84 1 (0.95) 4 (0.05) a74 S7 S4 (0.95) S7 (0.05) The corresponding changed equations for the two states s4 and s7 for which these two actions are prescribed by both policies are, V (s,) 0.95 7 VO s,) 0.05 1 V s,) Vs.) 0.95 7 V s,) 0.05 1 V s,) Using these equations, along with the others for 75g gives us the values, VG (44.812, 26.7722, 52.4787, 51.8647, 27.9173, 59.9073, 59.2932 And for 772g we get the values, "5G (38,2075, 24.7908, 45.8741, 45.8741, 25.3707, 53.3027, 52.9268 One can observe that increasing the chances of getting back to square one quickly does not do much for the expected costs. This is because the costs incurred in staying put at s4 and s7 are very low, and therefore the savings by avoiding them are low as well. Instead, if one were to increase the probability of action asg succeeding by ma