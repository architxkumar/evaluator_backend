de up of layers of fluents and actions, fp... p, actionsg , . We assume that it has access to the set of ground snap actions needed for planning as well as durations of actions. The algorithm begins by identifying actions that are in the event list E. For each such action e E, it marks the earliest completion time as 0 (lines 3-6). This implies that the corresponding end action e, can be added in this state. Further, the end action can be applied only at the earliest time the action can terminate at, represented by the predicate Earliest(e). It then proceeds to build the relaxed temporal planning graph in lines 7 to 21. It then identifies all snap actions that are applicable in that layer, and adds their positive effects in the next layer. For the new start actions it adds, it also updates their earliest ending times (line 15). In lines 16 to 21, it decides whether it needs to increment the time by or by the duration of the earliest completing action. 10.6 Trajectory Constraints and Preferences So far the goals that we have posed in the planning problems are constraints on a final state that the plan ends in. The only role that the plan found or the trajectory has been in evaluating the plan. We may prefer a plan which finishes the earliest, or a plan that in which the accumulated cost of actions is minimum, or a plan that uses a minimum amount of resources. We have not imposed any requirements on the plan itself. Trajectory constraints are a generalization of the specifying goal requirements on the final state and allow us to specify constraints a trajectory may need to satisfy in a valid plan. We look at some examples of trajectory constraints. In the cooking domain, one might want that whenever a stove is switched on, it must be switched off sometime. Or every time a refrigerator door is opened, it must be closed within a certain time. A student planning for her examination might be told that every two hours of study must be followed by a break for half an hour. 