s. C23) sim(qy, Cr4)4 ((1 430 50 100) (1 ( 40 80 100) (1 - ( 80 30)'100) (1 - (60 - 60 100))'4 (08 06 1.0 1.0) 4 0.85 sim(O,C,) (sim(q,. 3,) simlqy. 33) sitm(qs. 43) sim(qy. 53))4 ((1 30 90 100) (1 (40 40 100) (1 (50 50 100) (1 ( 60 60)'100)) 4 (0.4 1.0 1.0 1.0) 4 0.85 While C, differs from the query Q in all four attributes, C2 differs only on two, and C3 only on one attribute. But the one attribute C3 differs on, is by a large amount. It would thus be difficult to keep a range on the values of the attributes for retrieval. Suppose we kept a range ( - 10, - 10, - 10, 10) then only C, would be retrieved, even though the other two are considered equally similar. On the other hand, if we kept a larger range say, ( - 40, - 40, - 40, - 40), then some cases with low similarity will also be retrieved. For example, C4 (70, 80, 10, 20) would be retrieved, even though it has a similarity value of 0.6. Thus, while similarity search does allow the deviation of attribute values from the query values, it does not specify the amount of deviation for individual attributes. If one were to be doing threshold-based retrieval, the constraints are on the aggregated similarity value rather than on individual attribute similarities. We begin by describing how the KNN retrieval can be done sequentially. 15.2.2 Sequential Retrieval The simplest algorithm is to look at all the cases sequentially and maintain a retrieval set R that satisfies the required retrieval criteria. Figure 15.14 below describes the algorithm at a high level. The retrieval set R is maintained as a list of pairs, where each pair contains the case id and the value of similarity with the query Q. Let the case base contain N cases, let K and N be input parameters. The first line of the algorithm does a cursory check on the size N. If it is less than K then the entire case base is returned, sorted on similarity with the query Q. Otherwise, the first K cases are inserted into R. The rest of the cases are compared with Q seq