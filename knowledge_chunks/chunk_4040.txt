 goes along and to modify its behavior on the basis of the evidence. To model this behavior, we need a statistical theory of evidence. Bayesian statistics is such a theory. The fundamental notion of Bayesian statistics is that of conditional probability: PUHKE) Statistical Reasoning 173 ec RETa BENS Ie Read this expression as the probability of hypothesis H given that we have observed evidence E. To compute this, we need to take into account the prior probability of H (the probability that we would assign to H if we had no evidence) and the extent to which E provides evidence of H. To do this, we need to define a universe that contains an exhaustive, mutually exclusive set of H, s, among which we are trying to discriminate. Then, let P(H\E) = the probability that hypothesis H; is true given evidence E P(EMT,) = the probability that we will observe evidence E given that hypothesis / is true P(H,) = the a priori probability that hypothesis / is true in the absence of any specific evidence. These probabilities are called prior probabilities or priors. k = the number of possible hypotheses Bayes theorem then states that P(E\H,)-PCH;) PURE) = SE TT Di, PENH): PU, Suppose, for example, that we are interested in examining the geological evidence at a particular location to determine whether that would be a good place to dig to find a desired mineral. If we know the prior probabilities of finding each of the various minerals and we know the probabilities that if a mineral is present then certain physical characteristics will be observed, then we can use Bayes formula to compute, from the evidence we collect, how likely it is that the various minerals are present. This is, in fact, what is done by the PROSPECTOR program [Duda et al., 1979], which has been used successfully to help locate deposits of several minerals, including copper and uranium. The key to using Bayes theorem as a basis for uncertain reasoning is to recognize exactly what it says. Specifically, when we say 