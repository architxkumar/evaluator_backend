l. This system remembered thousands of board states and their estimated values. They provided the means to determine the best move to make at any point in the game. Samuel's system learns while playing the game of checkers, either with a human opponent or with a copy of itself. At each state of the game, the program checks to see if it has remembered a best-move value for that state. If not, the program explores ahead three moves (it determines all of. its possible moves: for each of these, it finds all of its opponent's moves: and for each of those, it determines all of its next possible moves). The program then computes an advantage or winvalue estimate of all the ending board states. These values determine the best move for the system from the current state. The current board state and its corresponding value are stored using an indexed address scheme for subsequent recall. The best move for each state is the move value of the largest of the minimums. based on the theory of two-person zero-sum games. This move will always be the best choice (for the next three moves) against an intelligent adversary. As an example of the look-ahead process, a simple two move sequence is illustrated in Figure 17.3 in the form of a tree. At board state K. the program looks ahead two moves and computes the value of each possible resultant board state. It then works backward by first finding the minimum board values at state K + 2 in each group of moves made from state K + I (minimums = 4. 3. and 2). These minimums correspond to the moves the opponent would make from each position when at state K + I. The program then chooses the maximum of these minimums as the best (minimax) move it can make from the present board Sec. 17.3 Checkers Playing Example 371 State K K*1 K+2 10 7 nin 4 3 mm 9 nn 2 2 Figure 17.3 A two-move Ioo Iheam J 2 sequence. state K (maximum = 4). By looking ahead three moves, the system can be assured it can do no worse than this minimax value. The board state and th