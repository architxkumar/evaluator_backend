8 upper(test) s 19 lower(test) s 20 for i lton 21 do if upper(i) lower (i) 2 then shrink 23 dower(i) Max(lower(i), (s simA(test, i) - 1)) 24 upper(i) Min(upper(i), (s - simA(test, i) 1)) 25 Re 26 for i lton 27 do if lower(i) T 28 then R RY GetCase (CB, i) 29 return R FIGURE 15.29 The Fish and Shrink algorithm to retrieve cases above a given threshold 7. While there are cases in contention, it picks (fishes) the best eligible case for computing similarity. It then updates (shrinks) the similarity bounds of all other cases. The complexity of the algorithm is quite high. One expects the number of similarity computations to be of order K, where K is the retrieval set size, irrespective of what criteria is used. This is because the best looking case is chosen in each cycle for similarity computation, and the bounds on the similarity value of each case become tighter in each cycle. However, after each similarity computation, all the N cases have to have their bounds updated. If each similarity computation costs C,), and each update costs Cupaate, then the average case complexity of retrieval is, T O(K Ceim) O(K N Cupdate) Observe that the two costs Cgim and Cupdate are constant, so the purist will say that the complexity is O(K N). But we would like to emphasize the fact that the algorithm should be used only when Cj is much larger than Cupaate. Then, if K is significantly smaller than N, it makes sense to highlight the fact that the similarity computation is done only order K times, even though all cases have their bounds updated repeatedly. 15.2.7 Case Retrieval Nets The algorithms seen so far have a backward chaining or goal directed flavour. Given the query Q, they search all the cases looking for the ones that best match the query. The Case Retrieval Net (Burkhard, 1998), (Lenz 1996, 1999), (Lenz and Burkhard, 1996) we study next is a structure that has a forwarding chaining flavour. The Case Retrieval Net (CRN) is a two stage, feed-forward network. It falls in the c