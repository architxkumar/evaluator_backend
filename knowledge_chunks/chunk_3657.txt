 that are easily transformed. To do this. we let each member of the population consist of a pair of triplets augmented with a utility value a, ((n1,n2.n3) (m,.m:.m3)u), where the first pair is the game state presented to the genetic algorithm system prior to its move, and the second triple is the state after the move. The a values represent the worth or current utility of the structure at any given time. Before the game begins, the genetic system randomly generates an initial population of K triple-pair members. The population size K is one of the important parameters that must be selected. Here, we simply assume it is about 25 or 30, which should be more that, the number of moves needed for any optimal play. All members are assigned an initial utility value of 0. The learning process then proceeds as follows. 1. The environment presents a valid triple to the genetic system. 2. The genetic system searches for all population triple pairs which have a first triple that matches the input triple. From those that match, the first one found having the highest utility value a is selected and the second triple is returned as the new game stale. If no match is found, the genetic system randomly generates a triple which represents a valid move, returns this as the new state. 378 Early Work in Machine Learning Chap. 17 and stores the triple pair, the input, and newly generated triple as an addition to the population. 3. The above two steps are repeated until the game is terminated, in which case the genetic system is informed whether a win or loss occurred. If the system wins, each of the participating member moves has its utility value increased. If the system lose!, each participating member has its utility value decreased. 4. The above steps are repeated until a fixed number of games have been played. At this time a new generation is created. The new generation is created from the old population by first selecting a fraction (say one half) of the members having the highest 