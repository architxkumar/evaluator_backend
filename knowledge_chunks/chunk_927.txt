retrieving K most similar cases as K Nearest Neighbour (KNN) retrieval. When CBR is used for classification then the solution could be the majority class label amongst the K retrieved cases. When solving a planning problem, a plan may be composed from components extracted from different cases in the retrieval set. For solving a troubleshooting (helpdesk) problem, one may use statistical information of problems encountered in the past to suggest the most likely solution from the retrieved set. One may also extend the case representation to include an Outcome field in addition to the Description and the Lesson. This contains the result of applying the lesson to the problem, and could be used to remind the user that a particular lesson did not work. In a way, it is like storing the utility of the case, and one would expect to use only high utility cases. This would be particularly useful in domains where the outcomes are stochastic, for example in foundrylike situations when the same manufacturing process sometimes yields defective products. One can then use statistical information from past usage to decide how likely the case is to be successful (see for example (Selvamani and Khemani, 2003)). To implement the CBR methodology, one has to address the following issues, 1. How are cases represented? This applies to both the description part and the lesson part. 2. How is the similarity between two descriptions computed? 3. How does one retrieve the desired cases efficiently? 4. How is the solution constructed from the lesson? An important issue is the problem description. The problem description is the one that defines the relevance of a case. One needs to ensure the utility distinguishability of the representation (Bergmann, 2002). This means that if the descriptions in two cases are identical then the corresponding lessons will have the same utility for any given problem. Equivalently, if the lessons in two cases have different utility values for a given problem then t