the delete effects are ignored, the resulting planning graph has no mutexes at all, because the mutexes are a direct consequence of having delete effects. Consequently, when the goal propositions are produced, the plan extraction phase can find a plan without the need to backtrack. This is because any set of actions that achieves a goal subgoal will be nonmutex. This means that a solution to the relaxed planning problem can be found in polynomial time (in terms of the number of propositions in the initial state, the number of planning operators, and the maximum size of the add list for these operators). Let the solution to the relaxed planning problem starting at state s be (At, Ag, ..., Am), where each A; is the set of actions in the layer that are part of the solution, and the goal propositions first appear in the m layer. Then the heuristic used by FF hFF simply counts the number of actions in the relaxed plan found. AFF(s) Fj 4, sm IAd Like HSP, the algorithm FF too does forward state space search and selects the node to expand, based on the heuristic values of the candidates. The best candidate node should ideally have the lowest value. However, the fact that the plan extraction phase happens without running into mutexes implies that it is not guaranteed that the plan extracted is the optimal one. In fact, as observed above, the task of finding the optimal plan is NP-hard. FF uses some heuristics while searching backwards to try and find the best plan. These heuristics are, 1. Prefer No-op Actions. f a No-op operation is available for supporting a proposition p then it is selected. In fact, this heuristic was also used in Graphplan, which first tries No-ops. 2. Difficulty Heuristic. lf a No-op action is not available to support the proposition, one of the other actions that produce p must be chosen. The difficulty heuristic says choose an action whose preconditions are the easiest to solve. The difficulty of an action is defined as follows, difficulty(a) geprec