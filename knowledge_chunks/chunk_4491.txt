ations for the various regions. Texture, illumination, and range 436 Artificial Intelligence data are all useful for this task. Assumptions about the kinds of objects that are portrayed can also be valuable, as we saw in the Waltz labeling algorithm (Section 14,3). Next, surfaces are collected into 3-D solids. Small solids are combined into larger, composite objects. At this point, the scene is segmented into discrete entities. The final step involves matching these entities against a knowledge base in order to pick the most likely interpretations for them. Organizing such a knowledge base of objects is difficult, though the knowledge-structuring techniques we studied in Part II are useful. As we demonstrated above, it may be impossible te interpret objects in isolation. Therefore, higher-level modules can pass hypotheses back down to lower-level modules, which check for predictions made by the hypotheses. This is only one way of structuring an image understanding program. It highlights the spectrum of lowto high-level knowledge required for 3-D vision. As with other AJ tasks, the success of a vision program depends critically on the way it represents and applies knowledge. For more information on computer vision, see Marr [1982], Ballard and Brown (1982], and Horn [1986]. 21.2.2 Speech Recognition [ Analog signal | Image analog-to-digital conversion 2-D features edge/region detection Y compute orientations 3-D features TABLE y group surfaces 3-D solids group solids 3-D composite objects match Y Object identifications ~ hypotheses Fig. 21.5 One Possible Architecture for Image Understanding Natural language understanding systems usually accept typed input, but for a number of applications this is not acceptable. Spoken language is a more natural form of communication in many human-computer interfaces. Speech recognition systems have been available for some time, but their limitations have prevented widespread use. Below are five major design issues in speech systems.