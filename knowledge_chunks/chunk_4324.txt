philosophers of computing, wrote that The Analytical Engine has no pretensions whatever to originate anything. It can do whatever we know how to order it to perform. [Lovelace, 1961] This remark has been interpreted by several AI critics as saying that computers cannot learn. In fact, it does not say that at all. Nothing prevents us from telling a computer how to interpret its inputs in such a way that its performance gradually improves. Rather than asking in advance whether it is possible for computers to learn, it is much more enlightening to try to describe exactly what activities we mean when we say learning and what mechanisms could be used to enable us to perform those activities. Simon [1983] has proposed that learning denotes .-changes in the system that are adaptive in the sense that they enable the system to do the same task or tasks drawn from the same population more efficiently and more effectively the next time. As thus defined, learning covers a wide range of phenomena. At one end of the spectrum is ski{l refinement. People get better at many tasks simply by practicing. The more you ride a bicycle or play tennis, the better you get. At the other end of the spectrum lies knowledge acquisition. As we have seen, many Al programs draw 348 Artificial Intelligence heavily on knowledge as their source of power. Knowledge is generally acquired through experience, and such acquisition is the focus of this chapter. Knowledge acquisition itself includes many different activities. Simple storing of computed information, or rote learning, is the most basic learning activity. Many computer programs, e.g., database systems, can be said to learn in this sense, although most people would not call such simple storage learning. However, many AT programs are able to improve their performance substantially through rote-learning techniques, and we will look at one example in depth, the checker-playing program of Samuel [1963]. Another way we learn is through taking advice 