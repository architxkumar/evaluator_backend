there is random noise in the data; rather the inaccuracies are systematic, and to uncover
themisanunsupervised learningprobleminvolving images, self-reported ages,andtrue(un-
known)ages. Thus,bothnoiseandlackoflabelscreateacontinuum betweensupervised and
unsupervised learning.
18.2 SUPERVISED LEARNING
Thetaskofsupervised learning isthis:
Givenatrainingsetof N exampleinput output pairs
TRAININGSET
(x ,y ),(x ,y ),...(x ,y ),
1 1 2 2 N N
whereeach y wasgenerated byanunknownfunction y f(x),
j
discoverafunction hthatapproximates thetruefunction f.
Here x and y can be any value; they need not be numbers. The function h isa hypothesis.1
HYPOTHESIS
Learningisasearchthrough thespaceofpossiblehypotheses foronethatwillperform well,
even on new examples beyond the training set. Tomeasure the accuracy of a hypothesis we
give it a test set of examples that are distinct from the training set. We say a hypothesis
TESTSET
1 Anoteonnotation:exceptwherenoted,wewillusejtoindexthe Nexamples;xjwillalwaysbetheinputand
yj theoutput. Incaseswheretheinputisspecificallyavectorofattributevalues(beginningwith Section18.3),
wewillusexj forthejthexampleandwewilluseitoindexthenattributesofeachexample. Theelementsof
xj arewrittenxj,1,xj,2,...,xj,n.
696 Chapter 18. Learningfrom Examples
f(x) f(x) f(x) f(x)
x x x x
(a) (b) (c) (d)
Figure18.1 (a) Example(x,f(x)) pairsand a consistent, linearhypothesis. (b)A con-
sistent,degree-7polynomialhypothesisforthesamedataset. (c)Adifferentdataset,which
admits an exact degree-6 polynomial fit or an approximate linear fit. (d) A simple, exact
sinusoidalfittothesamedataset.
generalizes well if it correctly predicts the value of y for novel examples. Sometimes the
GENERALIZATION
function f is stochastic it is not strictly a function of x, and what we have to learn is a
conditional probability distribution, P(Y x).
When the output y is one of a finite set of values (such as sunny, cloudy or rainy),
the learning problem is called classification, and is called Boolea