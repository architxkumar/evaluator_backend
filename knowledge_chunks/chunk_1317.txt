lions of years is the brain that will need many years to tune to the world. But we do not yet know how the years of sensory perception and symbolic (linguistic) instruction is accumulated in our heads. The key questions we feel that need to be answered before machine learning really kicks in is the one on the scaffolding or the conceptual structures that is needed to benefit from the learning experiences. The key questions are really of representation. A machine can learn a chess strategy only with explicit representation of chess moves, a a schema for strategy, and a goal (often implicit) of winning the game. Machine learning has been extremely successful in such well defined domain representations. To that extent it is an effective approach. But the process is long and painstaking. Strategies learnt over millions of episodes are useful only as long as the domain does not change. In that sense the learning is brittle. Because the representation that serve as the platform for learning are ad hoc. Yes, we have demonstrated that we can build systems that learn. And we can build useful applications that exploit this ability to learn. But we are still a far away from autonomous systems that will to survive in a world. The questions really are of representations. Humans learn from others and humans teach others. The medium is mostly natural language, though apprenticeship may play a role too. One test of how good the scheme of things is when computer systems are able to pass on what they have learnt to other computer systems. Would a chess playing program for example be able to go beyond communicating an evaluation function to another program? A related test is whether a machine learning system can teach a human being something. Can a world-champion chess program coach a bright young human into becoming a chess master? Or can a machine learning the bridge playing system learn the concept of a backwash squeeze? A counter question is that if can play it, does it really mat