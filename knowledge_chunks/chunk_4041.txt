lp locate deposits of several minerals, including copper and uranium. The key to using Bayes theorem as a basis for uncertain reasoning is to recognize exactly what it says. Specifically, when we say P(A\B), we are describing the conditional probability of A given that the only evidence we have is B. If there is also other relevant evidence, then it too must be considered. Suppose, for example, that we are solving a medical diagnosis problem. Consider the following assertions: S: patient has spots M: patient has measles F patient has high fever Without any additional evidence, the presence of spots serves as evidence in favor of measles. It also serves as evidence of fever since measles would cause fever. But suppose we already know that the patient has measles. Then the additional evidence that he has spots actually tells us nothing about the likelihood of fever. Alternatively, either spots alone or fever alone would constitute evidence in favor of measles. If both are present, we need to take both into account in determining the total weight of evidence. But, since spots and fever are not independent events, we cannot just sum their effects. Instead, we need to represent explicitly the conditional probability that arises from their conjunction. In general, given a prior body of evidence e and some new observation E, we need to compute P(el E, H) PCH\E, e) = P(HIE) - PCIE) 174 Artificial Intelligence Unfortunately, in an arbitrarily complex world, the size of the set of joint probabilities that we require in order to compute this function grows as 2 if there are n different propositions being considered. This makes using Bayes theorem intractable for several reasons: e The knowledge acquisition problem is insurmountable: too many probabilities have to be provided. In addition, there is substantial empirical evidence (e.g., Tversky and Kahneman [1974] and Kahneman et al. [(982]) that people are very poor probability estimators. e The space that would be required to 