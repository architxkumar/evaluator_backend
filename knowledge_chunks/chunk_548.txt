ions that produce p must be chosen. The difficulty heuristic says choose an action whose preconditions are the easiest to solve. The difficulty of an action is defined as follows, difficulty(a) geprecona(a) Min i proposition p occurs in layer i Given a choice of actions that achieve p, FF picks the one with the lowest difficulty value. The difficulty value for each action can be computed when it is first inserted in the planning graph. The reader will observe the similarity with the h (so, g), used by HSPr with g corresponding to precond(a). Hoffmann and Nebel (2001) report that they implemented their own version of Graphplan for solving the relaxed planning problem, without having to worry about mutex relations. When the planning graph is being constructed, each action and each proposition is marked with the layer in which it first appears. Armed with this information, the plan extraction phase can apply the above heuristics efficiently. The forward search used by FF is a greedy algorithm that is a variation of Hill Climbing, called Enforced Hill Climbing (EHC). The EHC algorithm is designed to work in domains in which from any given state, a better node is at most a few steps away. The basic idea is to search in a breadth first fashion till a better node is found, and when one is found, the algorithm moves to that node in a greedy manner. The algorithm, given in Figure 10.18, maintains a hash table of CLOSED nodes, and does not visit the same nodes again. EnforcedHillClimbing (state s, goal G, actions A) 1 plane ( ) 2 closed () 3 current s 4 h(current) HeuristicFF(current, Goal) S while h(current) 0 6 closed closed U current 7 PlanSegment NextBetter(current, closed, A) 8 9 if planSegment nix then return failure 10 else plan append (plan, planSegment) 11 current Last(current, planSegment) 12 h(current) heuristicFF(current, Goal) 13 closed Hashinsert(closed, planSegment) 14 return plan FIGURE 10.18 The procedure EnforcedHillClimbing synthesizes a plan using a greedy