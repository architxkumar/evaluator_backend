nformation. We will look at the process of automatically constructing indexing trees for structural CBR later in this chapter and also in the chapter on Machine Learning. RddConversation(case, tree) 1 on Root tree) 2 while not LeafNode(n) 3 do Lez be the question at node a 4 Le Abe the set cf answers 5 Let R be the answer tc in case, including don't know 6 if REA 7 then Create a new child c of n with answer 8 for ics edge a Acvtach vase to g return 10 else Let node m child(n such thay edge(n,m)is labeled with R 11 nem 12 reached a leaf containing a case o,., 13 Find some difference D between c,,, and case 14 Construct a questicn zo address the difference D 15 Store Q in node a 16 if c.,4 answers Q wich A, 17 then Create child n. with edge label A, and attach cy, to nm. 18 if case answer Q with Ay 19 then Create child n, with edge label A, and attach case to 7, FIGURE 15.10 A new case may be inserted in the case by starting at the root and answering the question stored there. The case follows the path where it has appropriate answers. When it does not have an answer, a new arc is created to accommodate the new case. If there are no more questions in the path, a new question is added. Given that there is no domain modelling in conversational CBR, there is also no notion of similarity. One could introduce a notion of similarity based on the location of two cases based on their location in the tree (see the section on structural CBR), but that is not sound because different trees can be constructed for the same cases. Furthermore, similarity is not used for retrieval. The greatest difficulty with this approach is that trees have to be handcrafted. In addition, maintenance is also cumbersome since the tree has to be edited manually. Conversational CBR would be useful when there is high traffic of consulting in a domain with small trees that can be handcrafted. For more complex domains, some explicit modelling of the domain could facilitate more flexible retrieval. In the