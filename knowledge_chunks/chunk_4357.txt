bels to positive (+). One drawback to the ID3 approach is that large, complex decision trees can be difficult for humans to understand, and so a decision tree system may have a hard time explaining the reasons for its classifications, Fig. 17.13 A Decision Tree 17.6 EXPLANATION-BASED LEARNING The previous section illustrated how we can induce concept descriptions from positive and negative examples. Learning complex concepts using these procedures typically requires a substantial number of training instances. 4 Actually, the decision tree representation is more general: Leaves can denote any of a number of classes, not just positive and negative. t i t [ i Learning 365 Peay mrp URERMNR ocd a OO Ve ORIDR RET * TRAN TEESE SEPTATE But people seem to be able to learn quite a bit from single examples. Consider a chess player who, as Black, has reached the position shown in Fig. 17.14. [yy alk The position is called a fork because the white knight attacks both the black king and the black queen. Black must move the king, thereby leaving the queen open to capture. From this single experience, Black is able to learn quite a bit about the fork trap: the idea is that if any piece x attacks both the opponent s king and another piece y, then piece y will be lost. We don t need to see dozens of positive and negative examples of fork positions in orderto [&|&{& draw these conclusions. From just one experience, we can learn to avoid this gv trap in the future and perhaps to use it to our own advantage. What makes such single-example learning possible? The answer, not surprisingly, is knowledge. The chess player has plenty of domain-specific knowledge that can be brought to bear, including the rules of chess and any previously acquired strategies. That knowledge can be used to identify the critical aspects of the training example. In the case of the fork, we know that the double simultaneous attack is important while the precise position and type of the attacking piece is not. Much