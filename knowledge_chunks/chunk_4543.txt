e could be an ordered chain of weights. One such is depicted in Fig. 23.12 for the network shown. Notice that each gene comprises the weights of the arcs that connect the neuron of a layer to those of its previous layer. Input Hidden Output Layer Layer Layer Wiz | Wo2 | Wia | W23 | Wis | W24 | W10 L wn] wai Wao | W30 weo | Figure 23.12 A Typical Artificial Neural Network and its Corresponding Chromosome Representation (The darkened lines indicate the gene boundaries} Here too the reciprocal of the sum of the squares of the errors reported after training the network for a predetermined number of epochs could dopict the fitness of a set of weights. Crossover can be effected by swapping the genes shown in Fig. 23.12. Mutation can be effected by randomly adding or subtracting a small value between 0 and | from the weights that comprise a randomly selected gene. With a population of such chromosomes, a fitness function, crossover and mutation probabilities, a GA can greatly aid in improving the search for a set of weights. 474 Artificial Intelligence 23.7 THEORETICAL GROUNDING Though the basic rudiments have been copied from nature, a theoretical proof always helps comprehension and refinement of these algorithms. It is thus essential to understand the theory on which these algorithms rest. Before we proceed to do so we define a few pertinent terms. 23.7.1 Schemata Sometimes referred to as similarity templates, schemata are basically the patterns of the solutions. For instance, if two solutions were represented in binary as 11011 and 01010, we observe that the inner three bits are the same in both the solutions. This means that both these solutions conform to the schemata *101* where the asterisks indicate don't cares (0 or 1). Just like a solution can conform to a schemata, a schemata too can correspond to several solutions. The schemata 10** could correspond to the solutions 1000, 1001, 1010 and 1011. Thus if the binary schema consists of n number of *s, it can corresp