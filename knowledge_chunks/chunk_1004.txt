ection 14.5). Similarly, one needs to have knowledge of how a cricket match is played, in order to be able to make sense of a news reporting how Sachin Tendulkar went on to score a century in a World Cup match. Encoding all relevant common sense and background knowledge and incorporating them appropriately in NLU systems has proved to be the holy grail of A . It is clear that we need to model the complex interaction of several phenomena to be able to understand how humans process natural language. In this respect, NLU is a scientific activity in a spirit very similar to natural sciences (like physics) where language is a natural artifact being studied, and the goal is to arrive at sophisticated models of language and its understanding. This involves the coming together of several disciplines like cognitive science, theoretical linguistics, psychology, machine learning and artificial intelligence. NLU is also an engineering activity, in that we attempt to build computational models that can make sense of textual data in the limited context of a given task or application. Several real world applications have been built; we will see examples of such applications later in this chapter. 16.1 Classic Problems in NLP and Schools of Thought While linguists are interested in characterizing languages and processes that account for its effective use, the field of Computational Linguistics (which we use interchangeably with Natural Language Processing) restricts attention to models that are realizable on a computer. The number of distinct English sentences is infinite. An idealized computer as conceptualized using a Turing Machine has a finite number of states, but can recognize (or accept) a language having infinite number of strings. On the surface, designing an automaton that can accept all English sentences and reject all invalid ones seems doable. In the light of the problems discussed in the introduction, however, defining the grammar would be incredibly challenging, and 