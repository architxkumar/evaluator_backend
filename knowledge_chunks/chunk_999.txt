ce. Explore the use of Manhattan distance, Euclidean distance, and the Minkowski norm to define similarity functions. What is their correspondence with the aggregation functions defined in this chapter? When will similarity between two cases be zero? The problem in Figure 15.12 involves matching colours, given their RGB values. Experiment with different colour matching functions on your computer, and compare with your visual judgment. Explore other colour representations like the HSV space that represents colours using values for Hue, Saturation and Value. 8. Study the case base in Table 15.3 and try and determine what combinations of factors are associated with a high salary. 9. Consider a case base in which all the attributes are Boolean. Explore the different distance functions that can be devised for two cases in his domain. 10. Modify the KNN algorithm in Figure 15.14 to return (a) all the cases n with highest similarity, and (b) all cases above a threshold similarity. 11. Using the function nsertK defined in Figure 15.23, rewrite the sequential KNN retrieval algorithm. 12. Can we think of the kd-tree as a taxonomy of cases? What are the similarities of kd-trees with taxonomies? What are the differences? 13. The algorithm for building a kd-tree in Figure 15.17 does not assign parent pointers at each node. Modify the algorithm to do so. Hint: Assign NIL parent to root and others in recursive calls. 14. Modify the algorithms Build-kdtree and KNN-kdtree to work with similarity values instead of distance values. 15. The KNN-kdtree algorithm applies the BOB test whenever it goes to a child node. Modify the algorithm to apply it only on leaf nodes. Which version is likely to run faster? 16. Specify the termination criteria and the precision line definition when the Fish and Shrink algorithm has to retrieve only the best cases. 17. Modify the Fish-and-Shrink-T algorithm for the KNN retrieval task. 18. Extend the Fish and Shrink algorithm to continue till the cases are