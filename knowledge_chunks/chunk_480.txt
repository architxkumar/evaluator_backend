t be useful is that the previous variable may not have imposed any constraint on the current dead-end variable. One simple way to infer that the previous variable did not impose a constraint that resulted in consistency is that it is not connected to the current variable in the constraint graph. When a search algorithm reaches a dead end at the variable x,,1 the algorithm GraphBackjumping assumes that the atest variable x, connected to x,41 in the constraint graph is the culprit. Observe that this may not lead to a maximal jump back because the real culprit may in fact be an earlier variable. GraphBackjumping does not keep track of values and conservatively assumes that x; is the culprit. Also, observe that GraphBackjumping will be safe only when all constraints explicitly show up in the constraint graph. If the variable x, is an internal dead end, the algorithm will jump back to the latest predecessor variable connected to either x; or x; The style of backjumping is illustrated in Figure 9.43, where the CSP of Figure 9.33 is attempted with the ordering CEABFDG. If the variable G were to be a dead end then the latest connected predecessor is F, but if F too does not have another value then the algorithm will jump back to E which is the next latest predecessor of G. FIGURE 9.43 GraphBackjumping. Given the left ordering, if G is a dead end, the algorithm jumps back to F. If that is an internal deadend, it jumps back to E, and then to C if needed. When the GraphBackjumping algorithm retreats from a variable xX, it uses a list of predecessors that it may need to jump back to. This list contains not only its own connected predecessors, but also that of any node in the future it is jumping back from. In the above figure, let the algorithm be about to jump back from the node F. If D were to be the leaf dead end that initiated the retreat for some assignment ar to variables C, E, A, Band F then it would jump back to F, and if F had no more values it would now go to C, becau