tion game so well that an average interrogator will not have more than 70 percent chance of making the right identification after five minutes of questioning. ... believe that at the end of the century, the use of words and general educated opinion will have altered so much, that one will be able to speak of machines thinking without expecting to be contradicted. Obviously, the Turing Test lays emphasis on the program behaving like a human. This means that a program participating in the test should conceal its abilities, like for example, to multiply very large numbers, or search through large amounts of information, or produce all anagrams of a given word in a jiffy. At the same time, it must display the kind of knowledge and language humans use, and engage in small talk about the weather, food prices and football scores. Some people feel that computers will never be able to do that, while others feel that the test is too simple. A chatterbot program called ELIZA, written by Joseph Weizenbaum (1966) in 1966, showed how human judgment is fallible. The most popular version of ELIZA is a program running the script Doctor, and can be found amongst other places in the emacs editor. Weizenbaum said that the program parodies the responses of a nondirectional psychotherapist in an initial psychiatric interview . He intended the program to be an exploration of natural language processing, but it was often taken too seriously by people who interacted with it. This was because the core of the program was to turn around the user's phrases. If you were to type m feeling sad , it would respond with something like Why are you feeling sad ? . Very often, if it did not know how to manipulate the current input, would resort to general questions like Tell me more about your family . It seems his secretary at MIT thought the machine was a real therapist, and spent hours revealing her personal problems to the program, only to be deterred when Weizenbaum told her (who was outraged at th