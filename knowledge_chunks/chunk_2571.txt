alk about the logical relationships among hypotheses,
exampledescriptions, andclassifications. Let Descriptions denotetheconjunction ofallthe
exampledescriptions inthetrainingset,andlet Classifications denotetheconjunction ofall
theexampleclassifications. Thena Hypothesis that explains theobservations mustsatisfy
thefollowingproperty (recallthat means logically entails ):
Hypothesis Descriptions Classifications . (19.3)
ENTAILMENT Wecall this kind of relationship an entailment constraint, inwhich Hypothesis is the un-
CONSTRAINT
known. Pure inductive learning means solving this constraint, where Hypothesis is drawn
from some predefined hypothesis space. For example, if we consider a decision tree as a
logicalformula(see Equation(19.1)onpage769),thenadecisiontreethatisconsistentwith
all the examples will satisfy Equation (19.3). If weplace no restrictions on the logical form
ofthehypothesis, ofcourse,then Hypothesis Classifications alsosatisfiestheconstraint.
Ockham s razor tells us to prefer small, consistent hypotheses, so we try to do better than
simplymemorizingtheexamples.
Thissimpleknowledge-freepictureofinductivelearningpersisteduntiltheearly1980s.
Themodernapproachistodesignagentsthatalreadyknowsomethingandaretryingtolearn
somemore. Thismaynotsoundlikeaterrificallydeepinsight,butitmakesquiteadifference
to the way we design agents. It might also have some relevance to our theories about how
scienceitselfworks. Thegeneralideaisshownschematically in Figure19.6.
Anautonomous learning agent thatusesbackground knowledge mustsomehow obtain
the background knowledge in the first place, in order for it to be used in the new learning
episodes. This method must itself be a learning process. The agent s life history will there-
fore be characterized by cumulative, or incremental, development. Presumably, the agent
could start out with nothing, performing inductions in vacuo like a good little pure induc-
tion program. But once it has eaten from the Tree of Knowledge, it c