le dice decides who plays first. After that, the players play alternately until one of them has moved all the checkers off the board. The decision making task of the player is, given the throw of a pair of dice, to choose from the set of moves allowed by the throw. One can think of the dice throw as randomly pruning the branching factor at each level, keeping only moves determined by the outcome of the throw. Traditional minimax based techniques cannot be used because one does not know the outcome of the throw by the opponent. Searching through all possibilities is also not feasible because there are 21 different outcomes of a throw of two dice, and each outcome typically allows around 20 moves. So the branching factor would be about 400, much larger than the game of Chess, and more like the branching factor in the game of Go. Not surprisingly, the techniques of Backgammon also rely heavily on evaluation. Two of the most successful Backgammon programs written by Gerald Tesauro illustrate two very different methods of learning the evaluation function. The first program called Neurogammon (Tesauro and Sejnowski, 1989) used a feed-forward neural network (see Figure 4.20) to learn the mapping between board positions and moves. Its input representation included both the raw board information (number of checkers at each location), as well as a few handcrafted features that encoded important expert concepts, plus a final position after the move. The output was a value of the move in the range -100, 100 . The program was trained by using the Backpropagation algorithm (Werber, 1994) on a set of recorded expert games. This is an example of supervised learning, in which the system is shown a set of desired values by an expert, and essentially learns a nonlinear function approximation representing the mapping between the input output pairs. Neurogammon was very successful and won the Backgammon championship at the 1989 International Computer Olympiad quite easily (Tesauro, 1989