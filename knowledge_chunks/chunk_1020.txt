t exploiting corpus statistics assigning the most likely sequence of tags to words in a sentence. A very popular scheme for stochastic tagging is the Hidden Markov Model (HMM) tagger. The idea behind HMM is discussed at length in Chapter 18. In the context of the current problem, the observed states are the words, and the POS tags constitute the hidden states. Stochastic taggers have been fairly successful with accuracies in the range of 95-96 . 16.2.6 Parsing Traditional Parsing Parsing is a well-studied area in the context of programming languages. However, as we noted earlier, parsers designed for programming languages are often not well suited for natural languages. This is because natural languages are inherently ambiguous, and at a syntax level, the number of valid parses for a sentence may sometimes exceed thousands. Knowledge of semantics, pragmatics or heuristics can be used to eliminate those that make no sense; this may still be a far cry, however, from realizing the goal of zeroing onto the one single parse that corresponds to the true intention of the author of the sentence. In traditional parsers, candidate parses are generated and a disambiguation module is used to choose the right parse based on additional information. There are some sentences that are fundamentally ambiguous, in the sense that even humans cannot disambiguate between candidate parses based on the available information. Parsing a sentence (string) in a language needs knowledge of its grammar. There are systematic patterns in the sentence that emerge from the knowledge of grammar. For example, sentences typically have constituent phrases like noun phrases and verb phrases. Words in a constituent like a noun phrase ( the old man and the sea ) occur close to each other. Parsing can be viewed as a search problem where the search space is the set of trees consistent with a given grammar. There are two extreme ways of performing this search: top down and bottom up. These two terms are used 