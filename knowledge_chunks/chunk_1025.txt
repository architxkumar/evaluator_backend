s that is only partially labelled with parse trees. This can be cast as a machinelearning problem where an inference has to be done in the presence of missing data. A classic approach is the Expectation Maximization (EM) algorithm outlined in Chapter 18. The application of EM algorithm to the problem of learning PCFG rules is discussed in (Manning et al., 1999). 16.2.7 Anaphora Resolution In discourse, it is typical to point backwards to a previously mentioned entity. This phenomenon is referred to as anaphora, with the item referring backwards as an anaphor and the item being referred to as an antecedent. Let us consider a simple example: Varun applied for several jobs in the banking sector. Unfortunately, he failed to qualify in any of them. Here, he in the second sentence is the anaphor pointing to the antecedent Varun. Detecting and resolving anaphora is important for NLP applications such as machine translation, text summarization and information extraction, which are covered in later sections of this chapter. Anaphora resolution techniques typically identify a set of candidate antecedents, one of which is selected based on several cues. The first of such cues is gender and number. In the example above, the set of candidate antecedents for resolving the pronoun he include Varun , several jobs and banking sector . The resolution concludes that he must refer to Varun , as it cannot refer to several jobs because of a number conflict, nor can it refer to banking sector because of a gender conflict. A second cue is selectional restraint, wherein background knowledge about the candidate antecedents can help prune the candidate set. An example is as follows: Anuradha s friends baked cakes. They were delicious. They, in the second sentence, must refer to cakes and not to the bakers; this is an example of semantic selectional restraint. It may be noted that the term anaphora has a broader connotation than just pronoun resolution. Examples of other kinds of anaphora incl