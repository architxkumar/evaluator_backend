vides descriptions of objects as defined by segmented edge structures. The descriptions created from this unit are represented as observation graphs. One output front predictor serves as an input Sec. 14.6 Vision System Architectures 319 algebra / user -... parser ---s.. predicto .r_ -edge mapping module graphicsqeometry iflterp rein / Figure 14.28 Main junctional nsge - inn finder .-edge rnappe, tinker components of ACRONYM to the edge mapping and linking module. This unit uses the predicted information (predicted edges, ribbons, or ellipses in the modeled objects) to assist in finding and identifying image objects appearing in the input image. Outputs from both the predictor and the edge mapper and linker serve as inputs to the interpreter. The interpreter is essentially a graph matcher. It tries to find the most matches among suhgraphs of the image observation graph and the prediction graph. Each match becomes an interpretation graph. Partial matching is accommodated in the interpretation process through consistency checks. The basic interpretation process is summarized in Figure 14.29 where models are given for two wide bodied aircraft. (a Boeing 747 and a Lockheed L-101 I). and the interpretation of an aircraft from gray-level image to ACRONYM's interpretation is shown. Ohta's Color Scene Analyzer Yuichi Obta or Kyoto University recently developed a vision system Which performs region analysis on outdoor color scenes (1986). Outdoor scenes typically include Objects such as trees, bushes, sky, roads, buildings, and other objects which are more naturally defined as regions rather than edges. His system makes use of the role color call in the segmentation process. Starting with tricolor (red, green, and blue) intensity arrays, digitized are produced from which regions are defined by a images The output of the segmentation process is a segmentation splitting process. two-dimensional array which identifies regions as commonly numbered pixel areas. This array is then