hich are drawn when they first appear as time increases from left to right (as in the planning graph). Since we are ignoring the delete effects, once a proposition has been generated it is always a part of all subsequent states. The length of each dashed line then is a measure of g(So, p). Now when the backward search regresses over the goal set, it produces candidate subgoal sets. In the figure, we illustrate two candidate sets SG7 and SG2 shown in shaded areas. The heuristic values for these subgoal sets can simply be aggregated from the values of the individual propositions which have been precomputed. Observe that the g(so, p) is always measured with respect to the start state so which is the destination of backward search. For example, if we were using the h then h (SG1) 3 2 3 8 and h (SG2) 3 2 1 6. FIGURE 10.17 HSPr precomputes 9(So, p) for every p, represented by dashed lines above. Then during a backward search, it needs to only aggregate the values for each proposition in a subgoal set. The dark nodes represent the goal and the two sets of three nodes represent the two subgoal sets. Another advantage of using backward search is that the branching factor is likely to be lower as compared to forward search as discussed in Chapter 7. However, as also described there, backward search has a disadvantage that it can generate spurious states, for example a blocks world subgoal in which the robot arm is holding two different blocks, or two different blocks are on a third block. Clearly, this is not possible and exploring such goals is an exercise in futility. HSPr strives to catch some of these spurious subgoals by computing a binary mutex between some pairs of propositions, in a manner similar to as is done while constructing the planning graph in Graphplan. The definition of mutex used in HSPr is (Bonet and Geffner, 2001). Given an initial state so and a set of ground operators A, a set M of pairs of propositions is a mutex set iff for all pairs R p, g M. 1. Both