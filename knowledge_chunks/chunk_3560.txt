rocesses used to find boundaries and regions, and to interpret color images is similar to that of gray-level systems. Although the additional computation required in color analysis can be significant, the added information gained from separate color intensity arrays may be warranted, depending on the application. In complex. scene analysis, color may be the most effective method of segmentation and object identification. In Section 14.6 we describe 4 Figure 14.11 Examples of textured surfaces. 298 Visual Image Understanding Chap. 14 Red 3reen _=_S H Fi Iter Figure 14.12 Color separation and processing. an interesting color scene analyser which is based on a rule based inferencing system (Ohta. 1985). Stereo and Optic Flow A stereoscopic vision system requires two displaced sensors to obtain two views of objects from different perspectives. The differences between the views makes it possible to estimate distances and derive a three-dimensional model of a scene. The displacement of a pixel from one image to a different location in another image is known as the disparity. It is the dispatity between the two views that permit the estimation of the distance to objects in the scene. The human vision system is somehow able to relate the two different images and form a correspondence that translates to a three-dimensional interpretation. Figure 14.13 illustrates the geometric relationships used to estimate distances to objects in stereoscopic systems. The distance k from the lens to the object can be estimated from the relationships that hold between the sides of the similar triangles. Using the relations i1 / e1 = f/ k, i / e, f/k, and d = e1 + e2 we can write k =fd/(j1 +i) Since f and d are relatively constant, the distance k is a function of the disparity, or sum of the distances it and i2. In computer vision systems, determining the required correspondence between the two displaced images is perhaps the most difficult part in determining the disparity. foci length of le