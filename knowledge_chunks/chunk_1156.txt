m her you would still have to worry about combining the evidences together, in a scenario where there may not be too much data on the conditional probabilities needed. This pull between modularity and reasoning under uncertainty is reflected in other places as well. Recall (Section 17.1) that while doing default reasoning, one has to minimize certain sets in the interpretation, and remove those formulas that that were not entailed by the KB. That could require one to look at the complete knowledge base as well. This is closer to the probability approach in which one has to sum up the entire knowledge (base). Logical reasoning by itself is modular. The antecedents and the rule imply the consequents. One difference between logical reasoning and probabilistic conditioning is that in logic there is an element of locality. For example, if one has the set of sentences, s PDQ QDR there is no difficulty in chaining the inferences because each rule has a local scope. The only thing one needs to infer Q is that S must be true, and in turn when Q is true, it is enough to conclude that R is true. Using probabilities on the other hand when we say that, P(Q S) 0.8 P(R Q) 0.7 we are really saying that, P(Q S, K) 0.8 P(RIQ, K) 0.7 where K captures all the unarticulated knowledge that contributed to assigning the values. And given S, it is not entirely clear how the probability of R being true would depend upon S being given, even though there appears to be a chain of reasoning. What we really need is the value for the conditional probability P(R Q, S). Given that we do not have that, and do not know with certainty that Q true, one approach would be to compute P(R) as a weighted average as follows, P(R) P(RIQ) P(Q) P(RI7Q) P(7Q) but this would need more data from the joint probability distribution. If we now take some new evidence E into account, then we would need to compute the posterior probabilities, P(RIE) P(RIQ, E) P(Q E) P(R 7Q, E) P(-Q E) but this changes the problem to a co