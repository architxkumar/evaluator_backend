nistic regardless oftheactualoutcome.
The belief state at each triangular node can be computed by applying a filtering al-
gorithm to the sequence of percepts and actions leading to it. In this way, the algorithm
takes into account the fact that, for decision A , the agent will have available percepts
t i
E , ..., E , even though at time t it does not know what those percepts willbe. In this
t 1 t i
way,adecision-theoretic agentautomatically takesintoaccountthevalueofinformation and
willexecuteinformation-gathering actionswhereappropriate.
A decision can be extracted from the search tree by backing up the utility values from
the leaves, taking an average at the chance nodes and taking the maximum at the decision
nodes. Thisissimilartothe EXPECTIMINIMAX algorithmforgametreeswithchancenodes,
except that (1) there can also be rewards at non-leaf states and (2) the decision nodes corre-
spond to belief states rather than actual states. The time complexity of an exhaustive search
todepthdis O( A d E d),where A isthenumberofavailable actionsand E isthenum-
ber of possible percepts. (Notice that this is far less than the number of depth-d conditional
666 Chapter 17. Making Complex Decisions
plans generated by value iteration.) For problems in which the discount factor is not too
close to 1, a shallow search is often good enough to give near-optimal decisions. It is also
possible to approximate the averaging step atthe chance nodes, by sampling from the set of
possibleperceptsinsteadofsummingoverallpossiblepercepts. Therearevariousotherways
offindinggoodapproximate solutions quickly, butwedeferthemto Chapter21.
Decision-theoreticagentsbasedondynamicdecisionnetworkshaveanumberofadvan-
tagescompared withother, simpleragentdesigns presented inearlierchapters. Inparticular,
theyhandlepartiallyobservable,uncertainenvironments andcaneasilyrevisetheir plans to
handle unexpected evidence. Withappropriate sensormodels, theycanhandle sensorfailure
andcanplantogatherinformation. Theye