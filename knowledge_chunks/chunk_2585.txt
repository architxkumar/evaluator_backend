tclassificationthenreturnfalse
storetheclassofe in H,indexedbythevaluesforattributes Aoftheexamplee
returntrue
Figure19.8 Analgorithmforfindingaminimalconsistentdetermination.
Sample Mass Temperature Material Size Conductance
S1 12 26 Copper 3 0.59
S1 12 100 Copper 3 0.57
S2 24 26 Copper 6 0.59
S3 12 26 Lead 2 0.05
S3 12 100 Lead 2 0.04
S4 24 26 Lead 4 0.05
The minimal consistent determination is Material Temperature Conductance. There
is a nonminimal but consistent determination, namely, Mass Size Temperature Conductance. Thisisconsistentwiththeexamplesbecausemassandsizedeterminedensity
and, inourdata set, wedonot have twodifferent materials withthe samedensity. Asusual,
wewouldneedalargersamplesetinordertoeliminateanearlycorrecthypothesis.
There are several possible algorithms for finding minimal consistent determinations.
Themostobviousapproachistoconductasearchthroughthespaceofdeterminations,check-
ingalldeterminations withonepredicate, twopredicates, andsoon, until aconsistent deter-
mination isfound. Wewillassumeasimple attribute-based representation, like thatusedfor
decision tree learning in Chapter 18. A determination d will be represented by the set of
attributesontheleft-handside,becausethetargetpredicateisassumedtobefixed. Thebasic
algorithm isoutlinedin Figure19.8.
The time complexity of this algorithm depends on the size of the smallest consistent
determination. Suppose thisdetermination has pattributes outofthe ntotalattr(cid:20)ib(cid:21)utes. Then
thealgorithmwillnotfindituntilsearchingthesubsetsof Aofsizep. Thereare n O(np)
p
Section19.4. Learning Using Relevance Information 787
1
0.9
0.8
0.7
0.6
0.5
0.4
0 20 40 60 80 100 120 140
tes
tset
no
tcerroc
noitropor P
RBDTL
DTL
Training set size
Figure 19.9 A performance comparison between DECISION-TREE-LEARNING and
RBDTL on randomly generated data for a target function that depends on only 5 of 16
attributes.
such subsets; hence the algorithm is exponential inthe size ofthe minimal determination. It
turn