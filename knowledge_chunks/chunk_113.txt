 E D F c fz D FI A State Q State P FIGURE 3.11 The first moves possible. A move consists of moving one topmost block to another place. In both cases, since there is a successor with a better heuristic value, the Hill Climbing algorithm will make a move. Let us look at the second move. In the first case, for h;, the algorithm is faced with the following choices for the second move, shown in Figure 3.12. We have named the states P and Start the same, though the search will see them as new choices. The heuristic values of the possible moves are given below. Search is at node Q, and all choices have a lower heuristic value. Thus, Q is a local maximum, and Hill Climbing terminates. h(Q) 1 14 14 14 (-1) 1 4 hy(P) (-1) 14 1 1 4 (-1) 1 2 hy(S) (-1) 1 14 14 (-1) 1 2 hy(U) 1 (-1) 14 14 (-1) 1 2 hy(V) 1 (-1) 14 14 (-1) 1 2 Meanwhile, the choices faced by the search using the second heuristic function hz, from state P, are shown below in Figure 3.13. Like in the previous case, two of the four choices result in states seen earlier. The heuristic values are ho(P) O 2414 04(1)40 2 ho(S) (-3) 241 0 (-1) 0 -1 ho(Q) (-2) 2 1 0 (-1) 0 0 ho(W 0 24 14 04(1) 0 2 ho(X) OF241404340 6 B A B c E A Dl F zE Pe Ip Fl State Q a IP ESI c E c e p Fl A p r State P Start FIGURE 3.12 The choices from state Q. B El Bl p Fl A State P N State X ERIC m im Si) ne B Cc E ic E Start FIGURE 3.13 The choices from state P. The search has a better option available in state X and moves to it. The reader can verify that in the next move it will reach the goal state. Thus, we see that the performance of the Hill Climbing algorithm depends upon the heuristic function chosen. One can think of the heuristic function defining a terrain over the search space, with each state having a heuristic value. While the strategy remains the same, that is the steepest gradient ascent (or descent, if the heuristic function is such that lower values are better), the performance depends upon the nature of the terrain being defined, 