ut, (3) the network is supplied with a real-valued judgment by the teacher, (4) the network adjusts its weights, and the process repeats. A positive value in step 3 indicates good performance, while a negative value indicates bad performance. The network seeks a set of weights that will prevent negative reinforcement in the future, much as an experimental rat seeks behaviors that will prevent electric shocks. 18.2.6 Unsupervised Learning What if a neural network is given no feedback for its outputs, not even a real-valued reinforcement? Can the network learn anything useful? The unintuitive answer is yes. 8. % hy So 2 s 4 4g a %o, 6, ys, CY Ye % & Be 4 By Dog Cat Bat Whale Canary Robin Ostrich Snake Lizard Alligator CODD COHHAAH SY ~s = OOCOCOO 00+++0000 4 &, eoo4#~++0+00 % +-c0000-000% Fig. 18.18 Data for Unsupervised Learning This form of learning is called unsupervised learning because no teacher is required. Given a set of input data, the network is allowed to play with it to try to discover regularities and relationships between the different parts of the input. Learning is often made possible through some notion of which features in the input set are important. But often we do not know in advance which features are important, and asking a learning system to deal with raw input data can be computationally expensive. Unsupervised learning can be used as a feature discovery module that precedes supervised learning. Consider the data in Fig. 18.18. The group of ten animals, each described by its own set of features, breaks down naturally into three groups: mammals, reptiles and birds. We would like to build a network that can learn which group a particular animal belongs to, and to generalize so that it can identify animals it has not yet seen. We can easily accomplish this with a six-input, three-output backpropagation network. We simply present the network with an input, observe its output, and update its weights based on the errors it makes. Without a teacher, 