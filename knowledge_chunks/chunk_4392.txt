ven two binary inputs, output | if exactly one of the inputs is on and output 0 otherwise. We can view XOR as a pattern classification problem in which there are four patterns and two possible outputs (see Fig. 18.12). Xt Xa | X1XOR x2 0 0 0 o 61 1 1 40 1 1 14 0 Fig. 18.12 A Classification Problem, XOR, That Is Not Linearly Separable The perceptron cannot learn a linear decision surface to separate these different outputs, because no such decision surface exists. No single line can separate the 1 outputs from the 0 outputs. Minsky and Papert gave a number of problems with this property including telling whether a line drawing is connected, and separating figure from ground in a picture. Notice that the deficiency here is not in the perceptron learning algorithm, but in the way the perceptron represents knowledge. lf we gould draw an elliptical decision surface, we could encircle the two 1 outputs in the XOR space. However, perceptrons are incapable of modeling such surfaces. Another idea is to employ two separate linedrawing stages. We could draw one line to isolate the point (x, = 1, x, = 1) and then another line to divide the remaining three points into two categories. Using this idea, we can construct a multilayer perceptron (a series of perceptrons) to solve the problem. Such a device is shown in Fig. 18.13. Note how the output of the first perceptron serves as one 7 of the second perceptron, with a large, negatively weighted -90 0.5 connection. If the first the input (x, = 1, x, = 1), Lt it will send a massive inhibitory pulse to perceptron, causing MLO TS LI FL that unit to output 0 regardiess of its other inputs. If either of alto the inputs is, 0, the second perceptron gets no inhibition . from the first perceptron, | if either of the inputs is 1. Fig. 18.13 A Multilayer Perceptron That Solves The use of multilayer perceptrons, then, solves our the XOR Problem knowledge representation problem. However, it introduces a serious learning problem. The convergenc