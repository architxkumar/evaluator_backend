he probability or belief in any sentence S can then be determined by summing the P1 over all W. in which Si is true. These notions can be represented using vector notation. We use the matrix V with L columns and K rows to represent the, truth values of the L sentences in each of the K sets W. The jsh column of V contains a one in row j if sentence S is true in W, and a zero if it is false. Also let the K-dimensional column vector p with components p,. i = I .....K. represent the possible world probabilities. With this notation, the product of V and p is a vector q which contains the probabilities of sentence S. for) = I .... . L. that is q = Vp (6.9) The jth component q1 of q is the sum of probabilities of the sets of possible worlds in which S is true, or the probabilistic truth value of S. As an example of this notation, the matrix equation for the consistent truth value assignments given in Table 6.1 is Sec. 6.4 Dempster-Shafer Theory 115 1 0 0 P11 q.= I .0 I I 1010 P4 where Pt. P2, p,. and p4 are the probabilities for the corresponding W. Thus, the sentence probabilities are computed as q1 = p(S1) = Pt + q2 p(S2) =p1 +p+p4 = p(S3) = Pt + Given a KB of sentences with known probabilities (obtained from an expert or other source), we wish to determine the probability of any new sentence S deduced from KB. Alternatively, we may wish to recompute some sentence probabilities in KB if new information has been gained which changes one or more of the original sentences in KB. To compute the probability of S requires that consistent truth values first be determihed for S for all sets of possible worlds. A new augmented matrix V can then be formed by adding a bottom row of ones and zeros to the original V where the ones and zeros correspond to the truth assignments. No methods have been developed for the computation of exact solutions for the KB sentence probabilities, although methods for determining approximations were presented for both small and large matrices V. We do