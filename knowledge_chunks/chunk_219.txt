r, it is amenable to parallel implementations, which would reduce execution time further. A simple way to do that would be to assign the different successors to different machines, each extending different partial solutions. The DA algorithm is described below in Figure 5.20. The algorithm uses a search bound captured in a variable named cutoff. The initial value of cutoff is set to the lower bound cost, as seen from the start node S. Since this is a lower bound, any solution found within cutoff cost must be optimal. The observant reader would have noticed that it is quite unlikely that the solution would be found in the first iteration when cutoff f(S). This is because the heuristic function is designed to underestimate the optimal cost. However, if the DFS search fails, in the next iteration the cutoff value is incremented to the next lowest Fvalue from the list OPEN. In this way, the value of cutoff is increased incrementally to ensure that in any iteration, only an optimal cost solution can be found. TDA () eutoff (S) h(S) while goal node is not found or no new nodes exist do use DFS search to explore nodes with f-values within cutoff if goal not found then extend cutoff to next unexpanded value if there exists one OR wr FIGURE 5.20 Algorithm Iterative Deepening A . While the algorithm IDA essentially does Depth First Search in each iteration, the space that it explores is biased towards the goal. This is because the fvalue used for each node is the sum of the g-value and the h-value. As for paths that are leading away from the goal, the h-values will increase and such paths would be cut off early. Thus, while DFS itself is without a sense of direction, the fact that Fvalues are used to prune the search pulls the overall envelope that it searches within towards the goal node as depicted in Figure 5.21. Like DFS, the space required of DA grows linearly with depth. We do not need to maintain a CLOSED list if we keep track of the solution path explicitly. There is,