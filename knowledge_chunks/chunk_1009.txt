portance to researchers in speech processing. Since the focus of this chapter is exclusively on processing of written (and not spoken) text, this topic is outside the scope of this chapter. Words come together to form bigger semantic units which we call sentences. For a sequence of words to form a sentence, they must be arranged in accordance with the rules of grammar. The meaning of a sentence is composed from the meanings of words. There are two important problems in NLP relating to this phenomenon of words coming together to form sentences. The first problem is: given a sentence, how do we break it up into chunks in a way that is consistent with the grammar of the language? This is the parsing problem. Figure 16.2 shows a sentence and its representation after it has been parsed. The sentence is: The idea that machines understand languages fascinates us . The second problem is to account for how the meaning of a sentence is composed from the meanings of the words in it. This is often referred to as compositional semantics to distinguish it from lexical semantics. As we have noted before, the notion of sentence meaning can get quite tricky. True understanding may need a wealth of background and linguistic knowledge, as also knowledge inferred from the context in which a sentence is uttered, and these can interact in complex ways. However, even as full scale understanding is an unsolved problem, there have been interesting techniques and knowledge representation formalisms that have been proposed towards addressing both the problems mentioned above. These will be covered in Section 16.2. Just as words come together to form sentences, sentences come together to form paragraphs or documents. The technical name for a group of sentences conveying some information is discourse. Understanding discourse is a grand challenge umbrella problem for NLP that encapsulates several long and short term problems. One immediate implication of effective discourse processing is that we