acktracking. A little later we look at approaches to jumping back to variables that may have been the cause of inconsistency that resulted in the backtracking. Observe that every time it moves forward to the next variable (steps 11 and 12), it makes a fresh copy of the domain. The algorithm Backtracking can abstractly be described as follows. Loop: 1. Select a variable. 2. Select a value for the variable. 2a. If none then undo some choices and reselect a previous variable. 2b. Else go to Loop. Steps 1, 2 and 2a contain the three choices the algorithm has to make. Each of them offers the possibility of making an informed choice. The choice at step 1 can be made such that some critical variables are assigned values early in search. We have already seen that the motivation for choosing a minimum induced width ordering is to arrange the variables such that future variables are constrained by as few parents as possible. In the next section, we will also see how the choice of variables is influenced dynamically by the current domain sizes of future variables. Having chosen a variable, the choice of a value for that variable at step 2 determines how future variable domains are affected. Some choices may leave more options for future variables. In the next section we look at varying degrees of lookahead that an algorithm can do to improve the choice at step 2. If the algorithm has reached a dead end, then in step 2a it needs to go back and try another value for an earlier variable. But the question is, which earlier variable? The inconsistency that caused the dead end could have been due to the choice of any variable assigned values in the past. Look-back approaches are designed to make this choice in an informed manner. We will look at them in Section 9.8. We will illustrate the algorithms with the CSP in Figure 9.33, which is a map colouring CSP on the constraint graph of Figure 9.29 shown here with the domains. The ordering chosen is GDBFEAC, which the reader would have 