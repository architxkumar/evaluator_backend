urrent, planSegment) 12 h(current) heuristicFF(current, Goal) 13 closed Hashinsert(closed, planSegment) 14 return plan FIGURE 10.18 The procedure EnforcedHillClimbing synthesizes a plan using a greedy approach moving to the first better node it finds. We assume the following functions: HeuristicFF(current, Goal) computes the heuristic function as described in the text; NextBetter(current, closed, A) finds the closest node that is better than the current node using breadth first search, avoiding the nodes in closed; Last(planSegment) progresses over the plan segment found and returns the final state reached; and Hashinsert(closed, planSegment) updates the table of closed nodes seen by EHC. The algorithm EHC commits to a better state as soon as it finds it. This may mean in some domains that it lands up in a dead end from where no moves are possible. Hoffman and Nebel observe that if EHC is going to fail, it fails pretty quickly. This means that FF can try something else to find a plan. After trying out some approaches based on randomization, they settled for a second stage in which they use a complete algorithm like Best First Search (see Chapter 3). One of the drawbacks of forward state space search is that the number of actions applicable in a given state may be quite large, as illustrated in Figure 7.4. Many of these actions may not be relevant to the goal being solved. While we do expect the heuristic function to select the better options from the set of candidates, computing the heuristic value for each such candidate adds to the computational overheads. FF has the option of using some pruning techniques which are quite effective, but not always be sound. This means that they may prune away a candidate node that would have been part of a solution. One such pruning method is the use of helpful actions. The set of helpful actions is the set A, in the relaxed plan (Aj, Ao, ..., Am) found by FF. The pruning method used is to consider only the actions in the helpful 