. And we do it with the aid of knowledge. Knowledge thus, has to be a key component for problem solving, if we are to build intelligent agents. 8.1.2 The Evaluation Function Since we cannot inspect the complete game tree and compute the minimax value, we have to resort to other means of selecting the move to make. If we could have computed the minimax value, we would have selected the move that would have been known to be the best move. Now instead, we have to look for methods with which we will select moves that appear to be the best. This is done by using a function to evaluate the goodness of a state, like we did with heuristic functions in Chapter 3. In game playing terminology, we call it the evaluation function, and it tells us how good a given position (state) is from the perspective of MAX. The outcome of a game is a value from the set -1, 0, 1 . The evaluation function, however, is usually applied to an intermediate node, and we are not in a position to choose a value from the set, since the game has not ended, and we cannot evaluate the full tree. Instead, we define the range of the evaluation function as the real interval -1, 1 . The extreme values 1 and 1 still represent wins for the two players. But other values estimate how close to winning each side is. For example, the value 0.5 says that MAX is better off than MIN, and 0.75 says that MAX is even more better off. A value of -0.9 says that MIN is doing very well. Note that the value zero says that both players are equally placed. It does not say that the game has ended in a draw. In practice, we extend the range to something like -10000, 10000 which is more conducive to devise evaluation functions. We will refer to it as -Large, Large . Where do we get the values from? This is where the knowledge of an expert comes in. Generally, the evaluation function is computed as a sum of values of different features, and we add or subtract values for each good feature or bad feature. This kind of knowledge may b