f weights (wo, 1, W2, .... W,) that will cause a perceptron to fire whenever the input falls into the first output class. Create a perceptron with n + 1 inputs and n + | weights, where the x) is always set to I. Initialize the weights (wo, w), ..., w,,) to random real values. Iterate through the training set, collecting all examples misclassified by the current set of weights. If all examples are classified correctly, output the weights and quit. Otherwise, compute the vector sum S of the misclassified input vectors where each vector has the form (xq, Xp... X,)- In creating the sum, add to S a vector x if Xis an input for which the perceptron incorrectly fails to fire, but X if is an input for which the perceptron incorrectly fires. Multiply sum by a scale factor 77. 6. Modify the weights (wo, w), .... w,,) by adding the elements of the vectort S to them. Go to step 3. WPw Yn The perceptron learning algorithm is a search algorithm. It begins in a random initial state and finds a solution state. The search space is simply all possible assignments of real values to the weights of the perceptron, and the search strategy is gradient descent. Gradient descent is identical to the hill-climbing strategy described in Chapter 3, except that we view good as down rather than up. So far, we have seen two search methods employed by neural networks, gradient descent in perceptrons and parallel relaxation in Hopfield networks. It is important to understand the relation between the two. Parallel relaxation is a problem-solving strategy, analogous to state space search in symbolic AJ. Gradient descentis a learning strategy, analogous to techniques such as version spaces. In both symbolic and connectionist Al, learning is viewed as a type of problem-solving, and this is why search is useful in learning. But the ultimate goal of learning is to get a system into a position where it can solve problems better. Do not confuse learning algorithms with others. The perceptron convergence the