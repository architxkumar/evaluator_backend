n-style computation. Connectionist AI is quite different from the symbolic approach covered in the other chapters of this book. At the end of this chapter, we discuss the relationship between the two approaches. 18.1 INTRODUCTION: HOPFIELD NETWORKS The history of AI is curious. The first problems attacked by AI researchers were problems such as chess and theorem proving, because they were thought to require the essence of intelligence. Vision and Janguage understandingprocesses easily mastered by five-year olds were not thought to be difficult. These days, we have expert chess programs and expert medical diagnosis programs, but no programs that can match the basic perceptual skills of a child. Neural network researchers contend that there is a basic mismatch between standard computer information processing technology and the technology used by the brain. In addition to these perceptual tasks, Al is just starting to grapple with the fundamental problems of memory and commonsense reasoning. Computers are notorious for their lack of common sense. Many people believe that common sense derives from our massive store of knowledge and, more important, our ability to access relevant knowledge quickly, effortlessly, and at the right time. When we read the description gray, large, mammal, we automatically think of elephants and their associated features. We access our memories by content. In traditional implementations, access by content involves expensive searching and matching procedures. Massively parallel networks suggest a more efficient method. Hopfield [1982] introduced a neural network that he proposed as a theory of memory. A Hopfield network has the following interesting features: 378 Artificial Intelligence SERRE ELTA MENGE TRESTLE NRE IEA LARTER, Distributed Representation A memory is stored as a pattern of activation across a set of processing elements. Furthermore, memories can be superimposed on one another; different memories are represented by different patte