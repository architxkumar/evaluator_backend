king of the correct candidates. Error detection as already mentioned could use either of the dictionary or the N-gram approaches. The possible correct candidates are found using a dictionary or by looking-up a pre-processed database of correct N-grams. Ranking of these candidates is done by measuring the texical or similarity distance between the misspelled word and the candidate. Minimum Edit Distance Technique Wagner [1974] defined the minimum edit distance between the misspelled word and the possible correct candidate as the minimum number of edit operations needed to transform the misspelled word to the correct candidate. By edit operations we mean insertions, deletions and substitutions of a single character (alphabet) to transform one word to the other. The minimum number of such operations required to effect the transform is commonly known as the Levenshtein distance named after Vladimir Levenshtein who first used this metric as a distance. As an example inspect the way in which you could transform the word drive (below) to the word time and arrive at the distance 3 between them. Db R I v E t t bi 1. Subs(D,T) 2. Delete(R) 3. Subst(V,M) Y Y Y 328 Artificial Intelligence A variant of the Levenshtein distance is the Damerau~Levenshtein distance which also takes into account the transposition of two characters in addition to insertion, deletion and substitution. (c) Context dependent Error detection and correction: These processes try, in addition to detect errors, try to find whether the corrected word fits into the context of the sentence. These are naturally more complex to implement and require more resources than the previous method. How would you correct the wise words of Lord Buddha Peace comes from within if it were typed as Piece comes from within ? Note that the first word in both these statements is a correct word. This involves correction of real-word errors or those that result in another valid word. Non-word errors that have more than one potential