ting symbols evoked the possibility of doing so intelligently and autonomously by the machine; and artificial intelligence became a lodestar for the pioneers of computing. The name artificial intelligence is credited to John McCarthy who, along with Marvin Minsky and Claude Shannon (1916-2001), organized the Dartmouth Conference in 1956. The conference was to be a two month, ten-man study of artificial intelligence ... on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described, that a machine can be made to simulate it. The above goal set the tone for the definition of artificial intelligence in the textbooks that appeared on the subject (see for example (Feigenbaum and Feldman, 1963), (Nilsson, 1971), (Newell and Simon, 1972), (Raphael, 1976), (Winston, 1977), (Rich, 1983) and (Charniak and McDermott, 1985)). Some definitions focus on human intelligence, and some on hard problems. We call programs intelligent , if they exhibit behaviours that would be regarded intelligent if they were exhibited by human beings Herbert Simon. Physicists ask what kind of place this universe is and seek to characterize its behaviour systematically. Biologists ask what it means for a physical system to be living. We (in Al) wonder what kind of information-processing system can ask such questions Avron Barr and Edward Feigenbaum (1981). Alis the study of techniques for solving exponentially hard problems in polynomial time by exploiting knowledge about the problem domain Elaine Rich. Alis the study of mental faculties through the use of computational models Eugene Charniak and Drew McDermott. Even while Charles Babbage was designing a mechanical computer, his collaborator Lady Ada Lovelace (1815-1852) had prudently observed that a machine can only do what it is programmed to do. This perhaps was an indicator of the debates that accompanied the foray into artificial intelligence (discussed briefly in a sect