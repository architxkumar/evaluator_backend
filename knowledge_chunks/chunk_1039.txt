nt meanings. It is possible that none of the real meanings is close to the average, leading to a serious distortion. Fourthly, both words and documents are treated in a uniform way by LSI. The concept features act as new dimensions, in terms of which both words and documents are represented. In Figure 16.13, which is an adapted version of Figure 18.3 from an online version of (Manning et al., 2008), we show an example of vectors spaces before and after LS . Figure 16.13(b) shows how representations of words and documents obtained by LS can be positioned in the new concept space. This allows us to visualize term and document clusters in the same space, and obtain interpretable descriptors of these clusters based on neighbouring words. Unemployment LSI dimension 2 Doc 3 o Doc 3 Unemployment oDoc 2 Poverty o Doc 2 Doc 1 Hunger Hunger LS! dimension (a) (b) Figure 16.13 Vector spaces before and after LSI. 16.3.3 Information Extraction The goal of Information Extraction (IE) is to automatically identify named entities like people, places and organizations, as well as events and relations between entities. Instead of attempting a full blown discourse understanding, Information Extraction operates over a restricted domain, and makes use of specific domain knowledge to elicit only certain kinds of information from text. The process of building an E system begins with a knowledge engineer describing the domain of interest using a template. An example of a template is shown in Figure 16.14 below. A template is basically a set of attributes (slots) and corresponding values (fillers). An interesting aspect of the template idea in E is its resemblance to structures proposed in literature on cognitive models of human memory. The process of understanding an article on an air crash involves invoking the template that captures salient aspects of a crash (when, where, number and type of casualties, for instance) and filling in this template, while also recording any significant additi