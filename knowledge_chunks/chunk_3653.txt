y inprove its performance. Simulated games between a CLA and various types p1 opponents have been performed and the results plotted Bock. 1985). It was shown, for example. that two CLAs playing against each other required about 300 games before each learned to play optimally. Note, however, that convergence to optimality can be accomplished with fewer games if the opponent always plays optimally (or poorly). since, in such a case, the CLA will repeatedly lose (win).and quickly reduce (increase) the losing (winning) no elements to zero one. It is also possible to speed up the learning process through the use of other techniques such as learned heuristics. Learning systems based on the learning automaton or CLA paradigm are fairly general for applications in which a suitable state representation scheme can be found. They are also quite robust learners. In fact, it has been shown that an LA will converge to an optimal distribution under fairly general conditions lithe feedback is accurate with probability greater than 0.5 (Narendra and Thathuchar. 1974). Of course, the rate of convergence is strongly dependent on the reliability of the feedback. Learning automata are not very efficient learners as was noted in the game playing example above. They are, however, relatively easy to implement. provided the number of states is not too large. When the number of states becomes large. the amount of storage and the computation required to update the transition matrix becomes excessive. Potential applications for learning automata include adaptive telephone routing and control. Such applications have been studied using sirnulationprograms (Narendra et al.. 1977). Although they have been given favorable recommendations. ie if any actual systems have been implemented. however. 17.5 GENETIC ALGORITHMS Genetic algorithm learning methods are bused on models of natural adaptation and evolution. These learning systems improve their performance through processes hich model population ge