ce of n observations x,, X2, -, X, and let Y be the corresponding label sequence Y y4, Y2,..., n2, which is often unknown or hidden from the user. Note that there is an order information associated with the sequence x Xq ... X,, where denotes occurs before relationship. The label y; outputs (observation x;. The Wikipedia defines a Hidden Markov Model as follows: An HMM is a statistical Markov model that is used to model a system that is assumed to a Markov process with hidden states. HMM models a sequence of labels, which is hidden and is not directly observable. For example, 1. In POS tagger, HMM models relationship between different parts of speech and is used in tagging a new sentence with appropriate POS tags. These tags are inferred from the observation sequence. 2. In an address segmentation problem, HMM models relationship between different portions of an address. Note that the portions of address are not directly available and needs to be inferred from the address based on prior experience. We are interested in learning a joint model between observation and label sequences. The HMM assumes that the observations are independent of each other and they depend only on the corresponding label, while labels are dependent on each other, as per the HMM specification. For example, i" observation x; is independent of all other data points and is dependent only on " label of the point. That is y;, which in turn depends on the label of the immediate predecessor y; ;. In the simplest case, the label of a point depends only on the label of its immediate predecessor. Such models are called first order Markov model. Under these models, P(yjly 1, Yo, ..-, i1) Plyjl i1) and the joint probability of X and Yis given by P(XY) PO) POY Ly) TP 2PO r P Od Yew) (18.14) It is possible to construct higher order HMMs. Their discussion is out of scope of this book. Interested readers can refer to (Bishop, 2006). Higher order HMMs are used for finding genes in the genome sequence and a bu