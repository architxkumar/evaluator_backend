it receives from the other neurons. The simplest model of the neuron applies some function to the weighted average of all the inputs. The output y; of the 4 neuron is given by, Y PR W yp (4.3) where x;,is the input received from the Kk" neuron, and w,; is the weight of the connection between the kK neuron and the neuron. In practice, the function used is Vy Py Wy ry FB) (4.4) where b is a bias, whose role becomes clear in Chapter 18, when we take up training. The function is a function applied to the weighted sum, and is known as an activation function which controls the output that the neuron generates. As we will see in Chapter 18, it is necessary that this function be a nonlinear function, if the network of neurons is to be able to do interesting computations. The simplest function is the Threshold function defined as follows, Ox) 1lifx20 (4.5) 0ifx 0 With this function, the neuron generates an output 1, when the input to it crosses the threshold 0 (the bias b plays a role here), and outputs 0 otherwise. This is also known as Heaviside function, and this model of the neuron is also known as the McCulloch-Pitts model after Warren S McCulloch and Walter Pitts who first described it (McCulloch and Pitts, 1943). Another function used is the sigmoid function, that we have seen earlier in Section 4.2. oO) WAte ) (4.6) where a is a slope parameter that controls the shape of the sigmoid function in a manner similar to what is done by the parameter T in Figure 4.6. Here, the output is not a step function, but a graded increase, asymptotically reaching the value 1. Many more refined models of the neuron have been created in an effort to model the biological neuron, keeping in mind that the output of the neuron is a temporal response in which a neuron generates output in a burst, only when certain conditions are met. That is beyond the scope of this text. But we are concerned with the fact that colonies of interconnected neurons become the complex information processing mac