close to A is likely to be out as well. The algorithm exploits this property as follows. Given a query Q, whenever the algorithm computes similarity with a test case T, it uses its knowledge of the similarity of T with other cases to update bounds on the similarity of all other cases with Q. Obviously, this will make sense only of the actual similarity computation is very expensive. If that is so, then the cost of visiting all cases and updating their similarity bounds will still be lower. This property is better illustrated when we deal with distances, again, like we did during kd-tree construction. Figure 15.25 below shows the relation between the distances of a test case T from the query Q, to another case C. These bounds will hold only when the distance function obeys the triangle inequality. ra . s fa CT) ) d(Q,T) Sac i oof i -OT H lower bound on d(Q, C H a - a H 1 Toe i upper bound on d(Q, C H FIGURE 15.25 Triangle inequality. Given the pre-computed distance a(C,T), the measurement d(Q,T) bounds the distance between Q and C. The triangle inequality says that given any three points X, Y and Z, the distances between the three satisfy the relations between the distances of the sides of a triangle. That is, a(X, Y) a(Y, Z) 2 (Xx, Z) The extreme case is when the three points are co-linear. Then, a(X, Y) a(Y, Z) a(X, Z) Using one extreme case (the lunar eclipse in the above figure) we get, a(Q, T) d(T, C) a(Q, C) the upper bound on a(Q, C) as d(Q, T) a(T, C). The other extreme case is when the point C is between Q and T, like in the solar eclipse, a(Q, C) A(T, C) d(Q, T) which gives us the lower bound on a(Q, C) as a(Q, 7) - d(T, C) as shown in the figure. Thus, a(Q, C) 2 a(Q, T) d(T, C) and a(Q, C) s a(Q, T) A(T, C) A small point to note about the triangle inequality is that it holds when the distances are unbounded. If the distance were to be normalized to the range 0,1 to define do 4)(X, Y), this relationship breaks down. For example, if the distance dio 1;(Q,7) 