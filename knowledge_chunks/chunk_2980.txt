 nontrivial environment on a nontrivial architecture. There would be little point in putting
enormous effort into finding BO rather than ABO programs, because the size and speed of
available machinestendstoincrease byaconstant factorinafixedamountoftimeanyway.
Wecan hazard a guess that BO or ABO programs for powerful computers in complex
environments willnotnecessarilyhaveasimple,elegantstructure. Wehavealreadyseenthat
general-purposeintelligencerequiressomereflexcapabilityandsomedeliberativecapability;
avarietyofformsofknowledgeanddecision making;learning andcompilationmechanisms
forallofthoseforms;methodsforcontrollingreasoning;andalargestoreofdomain-specific
knowledge. Abounded optimal agent must adapt tothe environment inwhich it findsitself,
so that eventually its internal organization will reflect optimizations that are specific to the
particular environment. This is only to be expected, and it is similar to the way in which
racing cars restricted by engine capacity have evolved into extremely complex designs. We
Section27.4. What If AI Does Succeed? 1051
suspect that a science of artificial intelligence based on bounded optimality will involve a
good deal of study of the processes that allow an agent program to converge to bounded
optimality andperhapslessconcentration onthedetailsof themessyprograms thatresult.
Insum,theconcept ofbounded optimality isproposed asaformaltaskfor AIresearch
thatisbothwelldefinedandfeasible. Bounded optimality specifies optimal programs rather
than optimal actions. Actions are, after all, generated by programs, and it is over programs
thatdesigners havecontrol.
27.4 WHAT IF AI DOES SUCCEED?
In David Lodge s Small World(1984),anovelabouttheacademicworldofliterarycriticism,
the protagonist causes consternation by asking a panel of eminent but contradictory literary
theorists the following question: What if you were right? None of the theorists seems to
haveconsideredthisquestionbefore,perhapsbecausedebatingunfalsifiabletheoriesisan