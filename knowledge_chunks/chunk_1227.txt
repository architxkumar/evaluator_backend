Find probability of a given sequence, X x;, Xp, -, X, where each xjex, being generated from a given HMM . The sequence X can be generated by traversing various paths in the Markov chain. Each path generates a sequence of labels with the corresponding probability of generating X. The probability is given by PMY, 0) Tear PO yea: O PC ye; (18.19) Note that yo B and y,4, E and these states do not emit any symbol. The quantity of interest can then be obtained by summing over all such probabilities. Let S be the set of all possible label sequences that generate X. P(X: 8) Zyes P(X: 6) (18.20) Dyes Mer POE P41: O PO 3: O (18.21) The key computational step here involves enumeration of all paths in the Markov chain. Clearly, such an operation is computationally inefficient and highly expensive. It can be efficiently carried out by storing intermediate results in order to avoid repetitive computations. The intermediate result at position i in the sequence can be calculated as follows. Pp Xys Xz. 5 XH) L PY ys Xy MYM (18.22) Using chain rule of probability, med POR 1X25 229 Kiet Jip VeD POY M9 Xa 0 Mp Vew P CD 2, Mev Yin) (18.23) rm Note that the symbol x; only depends on the label y; and hence, P(X; X, XQ. 5 Ke Mp Viv) PO; YD) Also, the label y; depends only on the label of previous state y; , and hence, PQ; y, XQ Ma Yer) PO; Viv) In addition, we will define a forward variable aj; ;(y; 1) that gives a total probability of observed sequence, up to i-1 symbol ending in the state y; 16Y. Let 10-1) PO. X2. Xe Yea) Equation (18.23) becomes PO). X45 XQ. 5 )) wey P 9) PO"1 i- Gai (18.24) PR; y ) ee POA Y- G0) (18.25) iL ay) (18.26) At Yp 1 E, we can simply compute P(X; 8) as follows. PUX: EPCELy,) (04) (18.27) We use a(B) 1. ForwardAlgorithm(HMM: H( ), Observations: X, Parameters: ) (B) 1 repeat for i lton for each y,cY a (ys) Plaslya) 2 P( ysl s-1) 0-1 (Yi-n) det n W PWN return P(X) 2 P(Ely,) ,(y,) , FIGURE 18.5 The ForwardAlgorithm is used to find the probability of a sequence X b