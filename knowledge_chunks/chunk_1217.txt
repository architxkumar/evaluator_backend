ids in a protein sequence, using a multinomial distribution. 2. We model length of proteins using a Gaussian distribution with parameters mean p and standard deviation o. Learning Estimate class priors and parameters of Multinomial and Gaussian distribution using the training data D. 1. The parameter corresponding to feature x(i) of multinomial distribution can be obtained for class f; can be obtained as follows: number of x ) in sequences of Sj Py 18.10 GMly D total number of observation sequences in f; ( ) The process needs to be repeated for all features across all k classes to obtain all the parameters of multinomial distribution. 2. The mean of protein length py needs to be estimated for each protein class. For class fj, it can be estimated as follows: My 1 lengtl(sequence) (18.11) number of sequences of class fj Git sequences of class t; The standard deviation sigma can be obtained as follows: 1 2 var, length J number of sequences of class Sj AD (18.12) i o, fear, (18.13) Inference Given the estimated model parameters, label a new sequence with an appropriate class label. 18.2 Inference in Bayesian Networks The Naive Bayes classifier assumes that the features are conditionally independent, given the class label. This assumption is often violated in practice. On the other hand, assuming that features are dependent on one another poses challenges in reliable estimation of parameters since enough data is not available. The Bayes network enables specification of dependencies between variables, thus offering a middle path solution. The fundamental concepts of a Bayesian network were covered in Chapter 17. In this chapter, we will study inference in Bayesian network. The simplest form of inference is using variable elimination, which we will study in detail in this chapter. General purpose inference schemes include junction tree algorithm and message passing over factor graph constructed from the belief network. Let us study a famous example, due to Judea Pearl, tha