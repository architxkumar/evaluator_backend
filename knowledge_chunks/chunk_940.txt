d(Y, Z) (triangle inequality). The maximum possible Hamming distance between two strings of length n, is n. Let h be the hamming distance between two strings. Then, the normalized hamming distance h is h n. Similarity between the two strings X and Y could then be defined as, sim, (X, Y) 1-h' 1-hi n Using this definition, the similarity between strings S; and Sis, simy (Sy, Sy) 1 -4 16 0.75 n-gram Similarity When we compare strings by mapping characters of one to the other, the outcome is critically dependent on the alignment. Further, insertion of even one character in the string, shifts the alignment of the entire remaining string. When strings are natural language word sequences, this can lead to similarity measures that are susceptible to large fluctuations with small changes. When an attribute contains text, the similarity between two strings should ideally be compared, based on the meaning of the text. For example, the two strings I feel like eating something and I am hungry represent a similar state of a person, and should be treated to be highly similar. But that requires deep semantic knowledge. We will look at other approaches to matching text documents in Chapter 16. Here we look at a simple approach of making text matching more robust. This is based on representing the string as a collection of n-grams, where each n-gram is a sequence of n characters that occurs consecutively in the string. Let the two strings X and Y be represented by sets of n-grams Ny and Ny. Ny X1, Xo, wey Xp Ny 4, Ya, 5 Yb Then, the n-gram similarity between X and Y is given by, N,N, N yD) The set representation does not take into account repeated occurrences of n-grams. We can extend this by treating the n-gram representation as bags, treating each occurrence as distinct. The set of common n-grams will have to take this into account. Observe that the set representation ignores the position in which n-grams occur. This is similar to the vector space representation for documents made 