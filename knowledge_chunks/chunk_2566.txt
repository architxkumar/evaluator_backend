program.
Withalargenumberofexamplesandalargespace, however,somedifficulties arise:
1. Checkingallthepreviousexamplesoveragainforeachmodificationisveryexpensive.
2. Thesearchprocessmayinvolveagreatdealofbacktracking. Aswesawin Chapter18,
hypothesis spacecanbeadoublyexponentially largeplace.
19.1.3 Least-commitment search
Backtracking arises because the current-best-hypothesis approach has to choose a particular
hypothesis as its best guess even though it does not have enough data yet to be sure of the
choice. What we can do instead is to keep around all and only those hypotheses that are
consistent with all the data so far. Each new example will either have no effect or will get
rid of some of the hypotheses. Recall that the original hypothesis space can be viewed as a
disjunctive sentence
h h h ... h .
1 2 3 n
Asvarioushypothesesarefoundtobeinconsistentwiththeexamples,thisdisjunctionshrinks,
retaining only those hypotheses not ruled out. Assuming that the original hypothesis space
does in fact contain the right answer, the reduced disjunction must still contain the right an-
swerbecauseonlyincorrecthypotheseshavebeenremoved. Thesetofhypothesesremaining
iscalledtheversionspace,andthelearningalgorithm (sketched in Figure19.3)iscalledthe
VERSIONSPACE
CANDIDATE versionspacelearningalgorithm (alsothe candidateelimination algorithm).
ELIMINATION
One important property of this approach is that it is incremental: one never has to
go back and reexamine the old examples. All remaining hypotheses are guaranteed to be
consistent with them already. But there is an obvious problem. We already said that the
774 Chapter 19. Knowledgein Learning
This region all inconsistent
G 1 G 2 G 3 . . . G m
More general
More specific
S 1 S 2 . . . S n
This region all inconsistent
Figure19.4 Theversionspacecontainsallhypothesesconsistentwiththeexamples.
hypothesisspaceisenormous,sohowcanwepossiblywritedownthisenormousdisjunction?
The following simple analogy is very helpful. How do you represent