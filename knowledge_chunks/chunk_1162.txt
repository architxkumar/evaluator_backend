 has appeared with the cake has the same effect of unblocking the path between X and Y. In the network in Figure 17.27, this would mean that knowing the value of X7 renders X3 and X, dependent. X Z Y fix a Some ace ( ae eee) ie oe watieg (a) height lability J Thy ility (b) ( (mood cele esult a fs food (c) (dice, ) (ice, ) A Figure 17.28 The three possible causal relations. Bayesian networks have been very popular in the area of pattern recognition and machine learning. The idea is similar to the kind of inferences in other network models. One freezes the values of some nodes in the network (the observations) and the task is to determine the posterior probabilities of other nodes in the network, via propagation through the edges. We shall look at some of the inferences that one can do with Bayesian networks in Chapter 18. 17.6 Stochastic Actions Another form of uncertainty is when actions are not deterministic. The planning algorithms we studied in Chapters 7 and 10 worked with planning operators which have well defined, deterministic effects. That implies that if the agent plans for an action a to be applied in a state S, then the agent is sure that the resulting state S is defined by (see Section 7.2), S 8 - effects (a) VU effects (a) The agent can then assume that it is in state S and continue planning from there. However, there are many domains in which the actions are not deterministic, which implies that the agent cannot project the actions into the future to discover the action sequences that work. The simplest examples of such actions are tossing a coin or throwing a dice. These are, in fact, random number generators, and one cannot predict the outcome deterministically. Other actions that have such a stochastic nature are throwing a basket ball towards the hoop; drawing a card ina game of blackjack; taking a step forward on slippery ice on a glacier; dialling a phone number (could result in a ring or an engaged tone); buying a lottery ticket; and making a fi