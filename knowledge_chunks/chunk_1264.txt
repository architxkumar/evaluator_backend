reased in proportion to the value of the feature v;. On the other hand, if the outcome is worse for MAX then the term is negative and the weights that contributed more are decreased. The parameter n is a learning rate parameter that is usually a small constant, for example 0.1. The value this parameter determines is how much the experience of the particular game influences the evaluation function. The basic idea is that good moves are reinforced over time as they reap rewards repeatedly, and an occasional blunder should not influence the other moves in that game drastically. In other words, a move in a given board position is deemed to be good, only after it proves itself in similar situations in many other games. The update rule of Eq. (18.52) is known to minimize the squared error between the training examples and values predicted by the evaluation function. It is known as the LMS (least means square) update rule. The basic algorithm for weight learning along the lines of the description in (Mitchell, 1997) is given in Figure 18.18. Weight-Learning (Moves: B,, B,, .., B, , Outcome: 0, weights: w,, w,,.. Wy ) 1 (B,) 0 2 for i n downto 2 3 for k 1 to K 4 Wy, wy, 1 (6(B,) (B,) v, 5 Recompute e(B.)) with the revised weights (Bia) e(B,)) 7 forkeltok 8 We O wy N (E(B,) - (By) vy 9 weturn M, W2,.. W FIGURE 18.18 The Weight-Learning algorithm is an example of TD-Learning. It adjusts the weights used in the evaluation function of the game by updating them in a direction that reduces the difference between current and new estimates of the evaluation function e(J). In Line 1, the outcome of the game played is assigned as a training value for the last board position in which MAX made a move. Then in Lines 2-8, the algorithm moves to previous board positions, updating each of the K weights using the LMS update rule. Finally, it returns the updated set of weights. 18.8 Artificial Neural Networks The field of Artificial Neural Networks (ANN) explores computer programs that are i