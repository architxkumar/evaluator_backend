n process, but they still require much effort on the part of domain experts. 17.7 SUMMARY We have examined examples of early work done in machine learning including perceptrons which learn through parameter adjustment, by looking at Samuel's checkers playing system which learns through a form of rote learning as well as parameter adjustment. We then looked at learning automata which uses a reward and punishment process by modifying their state probability transformation mapping structures until optimal performance has been achieved. Genetic algorithm systems learn through a form of mutation and genetic inheritance. Higher performing knowledge structures are mated and give birth to offspring which possess many of their parents' traits. Generations of structures are created until an acceptable level of performance has been reached. Finally, we briefly discussed Semiautonomous learning systems, the intelligent editors. These systems permit a domain expert to interact directly in building and refining a knowledge base without strong support from a knowledge engineer. EXERCISES 17.1. Given a simple perceptron with a 3-x.3 input sensor array, compute six learning cycles to show how the weights w change doting the learning process. Assign random weights to she initial w, values. 380 Early Work in Machine Learning Chap. 17 17.2. For the game of checkers with an assumed average number of 50 possible moves per board position, determine the difference in the total number of moves for a four move look-ahead as compared to a three move look-ahead system. 17.3. Design a learning automaton that selects TV channels based on-day of week and time of day (three evening hours only) for some family you are familiar with. 17,4. Write a computer program to simulate the learning automaton of the previous problem. Determine the number of training examples required for the system to converge to the optimal values. 17.5. Describe how a learning automaton could be developed to learn how to pla