is that the algorithm will make moves against the gradient too, but will have a higher probability of making better moves. Consider a maximization problem from which three states A, B and C are shown in Figure 4.4. Both A and B are maxima with B having a higher evaluation value. If the algorithm has to move from local maximum A to C, it will have a negative gain of AE,c. Likewise, if it has to move from B to C, it will have to go through a negative gain of AEgc. Since this is larger than AE, , it is likely that the algorithm moves from A to C more often than from B to C. Again, since the positive gain from C to B is higher; the algorithm is more likely to move from C to B than to A. That is, it is more likely that the algorithm will move from A to B than in the other direction. Then, given a series of local maxima of increasing magnitude, the search is likely to move towards the better ones over a period of time. AE FIGURE 4.4 To move from A to C, the algorithm has to incur a smaller loss than to move from B to C. Simulated Annealing is more likely to move from A to C to B than vice versa. One hopes, and this has been empirically supported by numerous applications, that by and large, the search will have a tendency to move to better solutions. The search may not perform very well on surfaces like in Figure 4.2 where IHC worked well, but for jagged surfaces with many maxima, like the one shown in Figure 4.5 below, it will probably do well. A randomized algorithm that has a simple and constant bias towards better values would be called Stochastic Hill Climbing. Simulated Annealing adds another dimension to this. It starts of being closer to the Random Walk, but gradually becomes more and more controlled by the gradient and becomes more and more like Hill Climbing. This changing behaviour is controlled by a parameter 7 called temperature. We associate high temperatures with random behaviour, much like the movement of molecules in a physical material. In Simulated Annea