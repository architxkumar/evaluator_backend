n CROSS-VALIDATION-WRAPPER(Learner,k,examples)returnsahypothesis
localvariables: err T,anarray,indexedbysize,storingtraining-seterrorrates
err V,anarray,indexedbysize,storingvalidation-seterrorrates
forsize 1to do
err T size ,err V size CROSS-VALIDATION(Learner,size,k,examples)
iferr T hasconvergedthendo
best size thevalueofsize withminimumerr V size return Learner(best size,examples)
function CROSS-VALIDATION(Learner,size,k,examples)returnstwovalues:
averagetrainingseterrorrate,averagevalidationseterrorrate
fold err T 0;fold err V 0
forfold 1to k do
training set,validation set PARTITION(examples,fold,k)
h Learner(size,training set)
fold err T fold err T ERROR-RATE(h,training set)
fold err V fold err V ERROR-RATE(h,validation set)
returnfold err T k,fold err V k
Figure18.8 Analgorithmtoselectthemodelthathasthelowesterrorrateonvalidation
data by building models of increasing complexity, and choosing the one with best empir-
ical error rate on validation data. Here err T means error rate on the training data, and
err V means error rate on the validation data. Learner(size,examples) returns a hypoth-
esis whose complexityis set by the parametersize, and which is trained on the examples.
PARTITION(examples,fold,k)splitsexamplesintotwosubsets: avalidationsetofsize N k
andatrainingsetwithalltheotherexamples.Thesplitisdifferentforeachvalueoffold.
18.4.2 From error rates to loss
So far, we have been trying to minimize error rate. This is clearly better than maximizing
error rate, but it is not the full story. Consider the problem of classifying email messages
as spam or non-spam. It is worse to classify non-spam as spam (and thus potentially miss
an important message) then to classify spam as non-spam (and thus suffer a few seconds of
annoyance). Soaclassifierwitha1 errorrate, wherealmost alltheerrorswereclassifying
spam as non-spam, would be better than a classifier with only a 0.5 error rate, if most of
thoseerrorswereclassifying non-spam asspam. Wesawin Chapter16thatdeci