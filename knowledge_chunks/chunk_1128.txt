 B and B . However since the former is a superset of the latter, it is discarded. Likewise, node M holds in two environments, C, D and E . Both these contribute to node Q which consequently holds in the two environments B, C, D and B, E . The reader should verify that these are minimal, and retracting any assumption would disrupt the corresponding environment. B c D E F G 4 7 UG DY LB IN (By Tone, DIENT, nogood: F, G w R) Ss 6 4 Dy BEY (2) B.C.) BB Figure 17.21 The environments for a set of statements. The small circles represent AND nodes. The contradiction node is named 1, and its environment is called a nogood. Contradiction L, ... , ... There may be several nogoods in the network and they represent the different combinations of assumptions that generate inconsistencies. In our example, the inference engine informs the ATMS that a contradiction resulted in the environment F, G . Consequently, the ATMS remembers the nogood F, G . Most implementations have a specific module for storing and querying nogoods. Now since F, G is a nogood, so is E, F, G being a superset of F, G . But E, F, G leads to node N, which would have been an alternate way of deriving node P. But since E, F, G is a nogood, it cannot be used, and in fact node N exists in the network without any justification. It must therefore be marked OUT. As a result, the node R too has no valid justification, and must also be marked OUT. The algorithm for computing the labels works in an incremental fashion as new nodes are given to the ATMS along with justifications. When a new inference is made, the new node is added with an empty label, and a two stage procedure begins. 1. The label of the new node is computed from the labels of its antecedents. 2. Any new labels are propagated across the network. We illustrate the two stages with an example. Let us say that first the following two nodes are added to the ATMS depicted in Figure 17.21. 7, (Ch, E, FY, (C , E, Fh U, B, C , B, G , B, C , B, G At this point, let