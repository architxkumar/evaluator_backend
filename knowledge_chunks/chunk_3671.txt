will often limit the size of the space as well. Consider the visual scene of Figure 18.3. When used as a training example for concepts like on top of, the difference in the size of the hypothesis space between representations based on primitive pixel values and more abstract Sec. 18.5 Inductive Bias 389 Figure 8.3 Blocks world scene. descriptions based on a semantic net can be very large. For example, a representation using only two levels of gray (light and dark) in a 1024 by 1024 pixel array will have a hypothesis space in excess of 210. Compare this with the semantic net space which uses no more than 10 to 20 objects and a limited number of position relationships. Such a space would have no more than 104 or 105 object-position relationships. We see then that the difference in the size of the search space for these two representations can be immense. Another simple example which limits the number of hypotheses is illustrated in Figure 18.4. The tree representation on the left Contains more information and, therefore, will permit a larger number of object descriptions to be created than with the tree on the right. On the other hand, if one is only interested in learning general descriptions of geometrical objects without regard to details of size, the tree on the right will be a superior choice since the smaller tree will result in less search. Methods based on the second general type of bias limit the search through preferential hypotheses selection. One way this can be achieved is through the use of heuristic evaluation functions. If it is known that a target concept should not contain some object or class of objects, all hypotheses which contain these objects can be eliminated from consideration. Referring again to Figure 18. 1, if it is known Any object Any object o Triangle Square Circle O'al Figure 18.4 Tree representation for object descriptions is small. I large). 390 Learning by Induction Chap. 18 that object 03 (or the description of 03) should not be inc