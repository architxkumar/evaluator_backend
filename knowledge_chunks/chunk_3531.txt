ct Learning ..,Jton Figure 13.1 The pattern recniton process I 274 Pattern Recognition Chap. 13 Decision Theoretic Classification The decision theoretic approach is based on the use of decision functions to classify objects. A decision function maps pattern vectors X into decision regions of D. More formally, this problem can be stated as follows. I. Given a universe of objects 0 = {o, 0,,..., o,,}, let each o have k observable attributes and relations expressable as a vector V = (V1. v2 .....vi). 2. Determine (a) a subset of m k of the v,, say X = (x1, whose values uniquely characterize the o, and (b) c 2 groupings or classifications of the o, which exhibit high intraclass and low interclass similarities such that a decision function I(X) can be found which partitions D into c disjoint regions. The regions are used to classify each o, as belonging to at most one of the c classes. Determining the feature attributes and decision regions requires stipulating or learning mappings from the measurement space M to the feature space F and then a mapping from F to the classification or decision space D, M i' F + D When there are only two classes, say C and C2. the values of the object's pattern vectors may tend to cluster into two disjoint groups. In this case, a linear decision function d(X) can often be used to determine an object's class. For example, when the classes are clustered as depicted in Figure 13.2, a linear decision function d is adequate to classify unknown objects as belonging to either C1 or C, where d(X) = WIXI + w..x, + w3 The constants w in d are parameters or weights that are adjusted to find a separating line for the classes. When a function such as d is used, an object is classified as belonging to C1 if its pattern vector is such that d(X) < 0. and as 000 0f07 * o o 0 o I/ + + o 0 o A' + + + C 000/++**++ c, 0 0 0/ + + o 7* + / + + -4oo I'+ I 000 ., +++++ 00/ +++ f d( X) + X2W2 * 0 Figure 13.2 A linear decision function. Sec. 13.2 The Recognition and 