n parallel Action-level parallelism, in which all of the actions of a single production are executed in parallel e Task-level parallelism, in which several cycles are executed simultaneously The amount of task-level parallelism available is completely dependent on the nature of the task. In a medical diagnosis system, for example, each production firing might be dependent on the previous production firing, thus enabling a long, sequential chain of reasoning to occur. However, if the system were diagnosing five patients simultaneously, productions involving different patients would not interact with one another and could be executed in parallel. Match-level parallelism is more widely applicable. Since production systems spend nearly all of their time in the matching phase, it was expected early on that match-level parallelism would lead to vast speedups. In a system with a thousand productions, for example, one processor could be assigned to every production, possibly speeding up every match cycle by a factor of a thousand. However, as Gupta [1985] showed, having n, processors does not lead to an n-fold speedup. Some reasons for this effect are: Parallel and Distributed Al 335 Ee 1, Only a few productions are affected by each change in working memory. With some bookkeeping to save state information, sequential implementations such as RETE [Forgy, 1982] (Section 6.4.2) can avoid processing large numbers of productions. Parallel implementations must be judged with respect to the speedups they offer over efficient sequential algorithms, not inefficient ones. 2. Some productions are very expensive to match, while others are cheap. This means that many processors may sit idle waiting for others to finish. When processors are idle, the speedup available from parallel processing diminishes. 3. Overhead resulting from communication costs among multiple processors can further reduce the benefits of parallelism. Other architectures behave differently with respect to parallel i