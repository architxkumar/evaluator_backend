e Multiple Locations Fig. 18.27 Distributed Representation Using Coarse Coding Connectionist Models 403 RAE AAS IAT BEI CAIRIT IO One drawback to distributed representations is that they cannot store many densely packed objects. A localist or symbolic system could easily represent the three distinct objects at (4 4), (4 5), and (5 4), but a distributed scheme would be confounded by the loss of information caused by the effect of many objects on a single unit s receptive field. On the other hand, psychological experiments have shown that a similar interference effect is very likely a cause of forgetting in human memory [Gleitman, 1981]. A more serious deficiency concerning distributed representations lies in the difficulty of interpreting, acquiring, and modifying them by hand. Thus, they are usually used in conjunction with automatic leaming mechanisms of the type discussed in Section 18.2, 18.6 CONNECTIONIST AI AND SYMBOLIC Al The connectionist approach to AI is quite different from the traditional symbolic approach. Both approaches are certainly joined at the problem; both try to address difficult issues in search, knowledge representation, and learning. Let s list some of the methods used by both: 1. Connectionist e Search Parallel relaxation. Knowledge Representation Very large number of real valued connection strengths. Structures often stored as distributed patterns of activation. Leaming Backpropagation, Boltzmann machines, reinforcement learning, unsupervised learning. 2. Symbolic e Search State space traversal. * Knowledge Representation Predicate logic, semantic frames, scripts. Learning Macro-operators, version spaces, explantion-leaming, discovery. The approaches have different strengths and weaknesses. One major allure of connectionist systems is that they employ knowledge representations that seem to be more learnable than their symbolic counterparts. Nearly all connectionist systems have a strong learning component. However, neural network learning al