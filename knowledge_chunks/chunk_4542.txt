 chromosome to contain longer sequences. We must bear in mind that the more the information contained within the chromosome, the more the computational time required to complete the search. Now that the chromosome is in place, we need to find a fitness function to evaluate them. A good fitness function should take into account network compactness, accuracy and learning rate. Considering all of them also contributes to computation costs. A simple and effective fitness function can thus be formulated using the reciprocal of the sum of the squares of the errors reported after training the network for a pre-determined number of epochs. The GA is now ready to run to aid you in the search for the (hopefully) optimal network topology. Genetic Algorithms: Copying Nature's Approaches 473 With the population size (number of neural networks), crossover and mutation probabilities and the number of epochs fixed a priori, the GA can now run, by training individual networks using small random weights and training patterns. After the fixed number of epochs, the fitness of each network is found and evaluated. Crossover is performed by randomly generating a row number and swapping corresponding rows of two networks. Mutation can be effected by changing a 0 to a | or vice versa in the chromosome thereby linking or unlinking two neurons. (b) Finding the Optimal Set of Weights One of the serious limitations of the most commonly used backpropagation algorithm is that it cannot guarantee an optima! convergence. In quite a few cases the algorithm manages to provide weights that lead to only a sub-optimal solution. Further, there is no method to recover from such local optima. Using a GA to find the set of optimal weights can help solve this problem to a great extent. The chromosome in this case could be an ordered chain of weights. One such is depicted in Fig. 23.12 for the network shown. Notice that each gene comprises the weights of the arcs that connect the neuron of a layer to those of