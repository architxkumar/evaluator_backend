 little from Graphplan, in that as it searches backward it also maintains a set of negative goal sets C; in layers j k preceding the last layer, along with subgoal sets G;. These negative goal propositions may be added to prevent undesirable conditional effects. We illustrate their utility with an example. Consider the example of the two students, Aditi and Jeena, mentioned above. Let one day the goal be (at aditi home), (at jeena school) , perhaps because Aditi was not well. Given that (at aditi home) is mutex with (at aditi school), it is imperative that the proposition (at aditi school) does not appear in the final layer. Otherwise, the goal set will not be nonmutex. Now we need the action busDrive(bus21, home, school) because we need to achieve (at jeena school) which is a conditional effect in that action. For this conditional effect to be achieved, the condition (in jeena bus) must be true in the (k 1) layer. There is an action board(jeena, bus) that would have achieved (in jeena bus) when both the bus and Jeena were at home . Thus, the plan would have two actions Jeena boards the bus, and the bus is driven to the school. But how does one ensure that Aditi has not landed up in school as a conditional effect of the same busDrive(bus21, home, school) action as well? IP2 can observe that the effect (at aditi school) interferes with the goal proposition (at aditi home) but it needs the busDrive(bus21, home, school). To ensure that Aditi does not land up in school, it adds a negative goal to the (kK -1) layer which says that (in aditi bus) is part of the negative goal set. The way such a negative goal is handled is that if there is any action that has it as an add effect then that action is not allowed in the backward search phase. Thus, while IP2 does select the busDrive(bus21, home, school) action, it constructs a plan which does not have the board(aditi, bus) action. The detailed algorithm is left as an (advanced) exercise for the reader. For hints and a stateme