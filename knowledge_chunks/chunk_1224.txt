 without specifying the corresponding label sequences. We will cover both these cases in this section. Training Data Consisting of Observation and Label Sequences The training data D consists of m ordered pairs of observation and label sequences (X;, Y;), (X2, Yo), -.-: (Xm, Ym) . In addition, the set of observation symbols S, the set of labels L and topology of HMM is provided as an input. With this set up, the objective is to determine transition probabilities in T and emission probabilities in O. Each row in T can be modelled using multinomial distribution. Formally, 7; Mult(g;). There are L 1 multinomial distributions and for each one L - 1 parameters need to be estimated. Since the state corresponding to label E does not have any connections to other states, we need not determine the corresponding parameters. Using maximum likelihood estimation (MLE), T(i, j) entry, corresponding to transition probability P(y; y,), can be estimated as follows. Y 2 0; - ; tansitions in , D) TO, D 6,5 POYb) (18.15) wy yeL (y, y; tansitions in X; D) In case of limited amount of training data, we do not encounter transitions between certain states and hence MLE of respective gj is zero, which drives probability of certain sequences being generated from the HMM to zero. The problem can be avoided by adding a small fake or pseudocount 0 in numerator and denominator of Eq. (18.15). Addition of pseudocount is nothing but Bayesian estimation using conjugate priors (Dirichlet distribution in this case). 7,40; y; transitions in. ;eD) 6 TU, D 9.5 POI) (18.16) a yeL Hy, - y; transitions in X; eD) 6 Similarly each row in O can be modelled appropriately depending on the nature of X. The X can be either discrete or continuous as described earlier. The discrete observations can be modelled using appropriate discrete distributions such as binomial, multinomial, Poisson, etc. On the other hand, the continuous or real observations can be modelled using distributions like Gaussian. The parameter es