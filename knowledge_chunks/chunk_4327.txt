 minimax search procedure to explore checkers game trees. As !The transitive closure of a program s knowledge is that knowledge plus whatever the program can logically deduce from it. Learning . 349 is the case with all such programs, time constraints permitted it to search only a few levels in the tree. (The exact number varied depending on the situation.) When it could search no deeper, it applied its static evaluation function to the hoard position and used that score to continue its search of the game tree. When it finished searching the tree and propagating the values backward, it had a score for the position represented by the root of the tree. It could then choose the best move and make it. But it also recorded the board position at the root of the tree and the backed up score that had just been computed for it. This situation is shown in Fig, 17.1] (a). Now suppose that in a later game, the situation shown in Fig. 17.1 (b) were to arise. Instead of using the static evaluation function to compute a score for position A, the stored value for A can be used. This creates the effect of having searched an additional several ply since the stored value for A was computed by backing up values from exactly such a search. Game Tree A L B Cc E|[F|[ ] [H]f {Kk [o|[R] [A] Stored Scores A: 10 10 (a) (b) Fig.17.1 Storing Backed-Up Values Rote learning of this sort is very simple. It does not appear to involve any sophisticated problem-solving capabilities. But even it shows the need for some capabilities that will become increasingly important in more complex learning systems. These capabilities include: Organized Storage of Information In order for it to be faster to use a stored value than it would be to recompute it, there must be a way to access the appropriate stored value quickly. In Samuel s program, this was done by indexing board positions by a few important characteristics, such as the number of pieces, But as the complexity of the stored information increases, mo