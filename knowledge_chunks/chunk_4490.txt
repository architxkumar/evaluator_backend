 important for interpreting visual data. For example, consider the ambiguous object at the center of Fig. 21.4(a). While no low-level image features can tell us what the object is, the object s surroundings provide us with top-down expectations. Expectations are critical for interpreting visual scenes, but resolving expectations can be tricky. Consider the scene shown in Fig. 21.4(b). All objects in this scene are ambiguous; the same shapes might be interpreted elsewhere as an amoeba, logs in a fireplace, and a basketball. As a result, there are no clear-cut top-down expectations. But the preferred interpretations of egg, bacon, and plate reinforce each other mutually, providing the necessary expectations. So how can we bring all of this knowledge to bear in an ? disk 0 ? sphere a | Ne ? dome Fig. 21.2 An Ambiguous Image Shadow & nel QO @ oe Texture Stereo C) 3 _ QO Motion & Q = 65 65 8 65 / 60 Range data 65 (60 50 60) 88 _ Q 65 \ 60.7% 65 65 65 65 Fig. 21.3. Using Low-Level Knowledge to Interpret an Image ID a C g Fig. 21.4 Using High-Level Knowledge ta Interpret an Image organized fashion? One possible architecture for vision is shown in Fig. 21.5. The very first step is to convert the analog video signal into a digital image. The next step is to extract image features like edge s and regions. Edges can be detected by algorithms that look for sets of adjacent pixels with differing values. Since pixel values are affected by many factors, small edges with similar orientations must be grouped into larger ones [Ballard and Brown, 1982], Regions, on, the other hand, are found by grouping similar pixels together. Edge and region detection are computationally intensive processes, but ones that can be readily mapped onto parallel hardware. The next step is to infer 3-D orientations for the various regions. Texture, illumination, and range 436 Artificial Intelligence data are all useful for this task. Assumptions about the kinds of objects that are portrayed can also be va