he unit above it. This unit. in turn. will attempt to activate the unit above ir, but the inhibitory connection from the upper-right unit will foil this attempt. and so on. This network has only four distinct stable states, which are shown in Fig. 18.2. Given any initial state, the network will necessarily settle into one of these four configurations.' The network can be thought of as storing the patterns in Fig. 18.2. Hopfield s major contribution was to show that given any set of weights and any initial state, his parallel relaxation algorithm would eventually steer the network into a stable state. There can be no divergence or oscillation. Fig. 18.2 The Four Stable States of a Particular Hopfield Net 'The stable state in which all units are inactive can only be reached if it is also the initial state. Connectionist Models 379 PAS RRIRLOELIATESE PHONEMIC RD s O BAL OR Ae SNES ao The network can be used as a content-addressable memory by \ setting the activities of the units to correspond to a partial pattern. To retrieve a pattern. we need only supply a portion of it. The Ae network will then settle into the stable state that best matches the partial pattern. An example is shown in Fig. 18.3. Parallel relaxation is nothing more than search, albeit of a A J different style than the search described in the early chapters of \ this book. It is useful to think of the various states of a network as . . forming a search space, as in Fig. 18.4. A randomly chosen state Figs 18.3 A Hopfield Net as a Model of will transform itself ultimately into one of the /ocal minima, namely Content-Addressable Memory the nearest stable state. This is how we get the content-addressable behavior.? We also get error-correcting behavior, Suppose we read the description, gray, large, fish, eats plankton. We imagine a whale. even thougb we know that a whale is a mammal, not a fish. Even if the initial state contains inconsistencies, a Hopfield network will settle into the solution that violat