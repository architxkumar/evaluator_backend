packaging up a procedure and a list of arguments that together
define what should be done next whenever the current goal succeeds. It would not
do just to return from a procedure like APPEND when the goal succeeds, because it
could succeed in several ways, and each of them has to be explored. Thecontinuation
argument solves this problem because it can be called each time the goal succeeds. In
the APPEND code, ifthe firstargument is empty and the second argument unifies with
the third, then the APPEND predicate has succeeded. We then CALL the continuation,
with the appropriate bindings on the trail, to do whatever should be done next. For
example, if the call to APPEND were at the top level, the continuation would print the
bindingsofthevariables.
342 Chapter 9. Inference in First-Order Logic
Before Warren s work on the compilation of inference in Prolog, logic programming was
too slow for general use. Compilers by Warren and others allowed Prolog code to achieve
speeds that are competitive with C on a variety of standard benchmarks (Van Roy, 1990).
Of course, the fact that one can write a planner or natural language parser in a few dozen
linesof Prologmakesitsomewhatmoredesirablethan Cforprototypingmostsmall-scale AI
research projects.
Parallelizationcanalsoprovidesubstantialspeedup. Therearetwoprincipalsourcesof
parallelism. The first, called OR-parallelism, comes from the possibility of agoal unifying
OR-PARALLELISM
withmanydifferentclausesintheknowledgebase. Eachgivesrisetoanindependent branch
in the search space that can lead to a potential solution, and all such branches can be solved
in parallel. The second, called AND-parallelism, comes from the possibility of solving
AND-PARALLELISM
each conjunct inthebody ofanimplication inparallel. AND-parallelism ismoredifficult to
achieve, because solutions for the whole conjunction require consistent bindings for all the
variables. Each conjunctive branch must communicate with the other branches to ensure a
globalsoluti