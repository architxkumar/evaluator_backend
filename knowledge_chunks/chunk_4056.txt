e [0,1]. As evidence is accumulated, this interval can be expected to shrink, representing increased confidence that we know how likely each hypothesis is. Note that this contrasts with a pure Bayesian approach, in which we would probably begin by distributing the prior probability equally among the hypotheses and thus assert for each that P(/) = 0.33. The interval approach makes it clear that we have no information when we start. The Bayesian approach does not, since we could end up with the same probability values if we collected volumes of evidence, which taken together suggest that the three values occur equally often. This difference can matter if one of the decisions that our program needs to make is whether to collect more evidence or to act on the basis of the evidence it already has. So far we have talked intuitively about Be? as a measure of our belief in some ,, hypothesis given some evidence. Let s now define it more precisely. To do this, we need to start, just as with Bayes theorem, with an exhaustive universe of mutually exclusive hypotheses. We'll call this the frame of discernment and we'll write itas . For example, in a simplified diagnosis problem, might consist of the set {All, Flu, Cold, Pneu]: All: allergy Flu: flu Cold: cold Pheu: pneumonia 182 Artificial Intelligence eect RETIN, Our goal is to attach some measure of belief to elements of . However, not all evidence is directly supportive of individual elements. Often it supports sets of elements (i.e., subsets of ). For example, in our diagnosis problem, fever might support { Flu, Cold, Pneu}. In addition, since the elements of are mutually exclusive, evidence in favor of some may have an affect on our belief in the others. In a purely Bayesian system, we can handle both of these phenomena by listing all of the combinations of conditional probabilities. But our goal is not to have to do that. Dempster-Shafer theory lets us handle interactions by manipulating sets of hypotheses directly. The k