 a decision to terminate the path is made. It makes sense to terminate a path if it reaches a dead-end, produces a previous state, or becomes longer than some prespecified futility limit. In such a case, backtracking occurs. The most recently created state from which alternative moves are available will be revisited and a new state will be created. This form of backtracking is called chronological backtracking because the order in which steps are undone depends only on the temporal sequence in which the steps were originally made. Specifically, the most recent step is always the first to be undone. This form of hacktracking is what is usually meant by the simple term bucktracking. But there are other ways of retracting steps of a computation. We discuss one important such way, dependency-directed backtracking. in Chapter 7. Until then, though, when we use the term backtracking, it means chronological backtracking. The search procedure we have just described is also called depth-first search. The following algorithm describes this precisely. Algorithm: Depth-First Search 1. If the initial state is a goal state, quit and return success. 2. Otherwise, do the following until success or failure is signaled: (a) Generate a successor, E, of the initial state, If there are no more successors, signal failure. (b) Call Depth-First Search with E as the initial state. (c) If success is returned, signal success. Otherwise continue in this loop. Figure 2.7 shows a snapshot of a depth-first search for the water jug problem. A comparison of these two simple methods produces the following observations: (0,0) _ - [14.9) [49 | \ Fig. 2.7 A Depth-First Search Tree Advantages of Depth-First Search Depth-first search requires less memory since only the nodes on the current path are stored. This contrasts with breadth-first search, where all of the (ree that has so far been generated must be stored. By chance (or if care is taken in ordering the alternative successor states), depth-first 